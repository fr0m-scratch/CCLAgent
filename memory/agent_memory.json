{
  "rules": [
    {
      "confidence": 0.17433922005000008,
      "config_patch": {
        "NCCL_BUFFSIZE": 6291456,
        "NCCL_PROTO": "LL128"
      },
      "context": {
        "extra": {},
        "framework": null,
        "gpu_type": null,
        "gpus_per_node": null,
        "model": null,
        "network": null,
        "nic_count": null,
        "nodes": 1,
        "scale": "unknown",
        "topology": "unknown",
        "workload": "demo",
        "workload_kind": "workload"
      },
      "created_at": "2026-02-02T16:59:39.813080Z",
      "evidence": {},
      "id": "c8d643da-b4ba-4030-bfb9-c64fd6de3996",
      "improvement": 0.09756097560975599,
      "last_used": null,
      "rule_type": "positive",
      "source": "online_tuning",
      "tries": 0,
      "wins": 0
    },
    {
      "confidence": 0.17433922005000008,
      "config_patch": {
        "NCCL_BUFFSIZE": 6291456,
        "NCCL_PROTO": "LL128"
      },
      "context": {
        "extra": {},
        "framework": null,
        "gpu_type": null,
        "gpus_per_node": null,
        "model": null,
        "network": null,
        "nic_count": null,
        "nodes": 1,
        "scale": "unknown",
        "topology": "unknown",
        "workload": "demo",
        "workload_kind": "workload"
      },
      "created_at": "2026-02-02T16:59:39.814536Z",
      "evidence": {
        "baseline_ms": 1066.0,
        "best_ms": 962.0000000000001,
        "history_count": 9,
        "improvement": 0.09756097560975599,
        "records": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8
        ]
      },
      "id": "12376c23-b68c-45fc-a853-ad435bc20f2c",
      "improvement": 0.09756097560975599,
      "last_used": null,
      "rule_type": "positive",
      "source": "online_tuning",
      "tries": 0,
      "wins": 0
    },
    {
      "confidence": 0.405,
      "config_patch": {
        "NCCL_ALGO": "TREE",
        "NCCL_NTHREADS": 192,
        "NCCL_PROTO": "LL"
      },
      "context": {
        "extra": {},
        "framework": null,
        "gpu_type": null,
        "gpus_per_node": null,
        "model": null,
        "network": null,
        "nic_count": null,
        "nodes": 1,
        "scale": "unknown",
        "topology": "unknown",
        "workload": "demo",
        "workload_kind": "workload"
      },
      "created_at": "2026-02-02T18:46:17.591107Z",
      "evidence": {},
      "id": "9d1fe8ba-f2fe-4e41-87e5-2c584744490b",
      "improvement": 0.05182341650671785,
      "last_used": null,
      "rule_type": "positive",
      "source": "online_tuning",
      "tries": 0,
      "wins": 0
    },
    {
      "confidence": 0.405,
      "config_patch": {
        "NCCL_ALGO": "TREE",
        "NCCL_NTHREADS": 192,
        "NCCL_PROTO": "LL"
      },
      "context": {
        "extra": {},
        "framework": null,
        "gpu_type": null,
        "gpus_per_node": null,
        "model": null,
        "network": null,
        "nic_count": null,
        "nodes": 1,
        "scale": "unknown",
        "topology": "unknown",
        "workload": "demo",
        "workload_kind": "workload"
      },
      "created_at": "2026-02-02T18:46:17.592047Z",
      "evidence": {
        "baseline_ms": 1042.0,
        "best_ms": 988.0,
        "history_count": 5,
        "improvement": 0.05182341650671785,
        "records": [
          0,
          1,
          2,
          3,
          4
        ]
      },
      "id": "893bbdbb-921d-4912-b2e8-c5ba610eaa21",
      "improvement": 0.05182341650671785,
      "last_used": null,
      "rule_type": "positive",
      "source": "online_tuning",
      "tries": 0,
      "wins": 0
    },
    {
      "confidence": 0.5,
      "config_patch": {
        "NCCL_BUFFSIZE": 6291456
      },
      "context": {
        "extra": {},
        "framework": null,
        "gpu_type": null,
        "gpus_per_node": null,
        "model": null,
        "network": null,
        "nic_count": null,
        "nodes": 1,
        "scale": "unknown",
        "topology": "unknown",
        "workload": "demo",
        "workload_kind": "workload"
      },
      "created_at": "2026-02-02T18:46:23.048757Z",
      "evidence": {},
      "id": "bde6c1ba-b926-454b-a400-e3a925e62572",
      "improvement": 0.15313653136531366,
      "last_used": null,
      "rule_type": "positive",
      "source": "online_tuning",
      "tries": 0,
      "wins": 0
    },
    {
      "confidence": 0.5,
      "config_patch": {
        "NCCL_BUFFSIZE": 6291456
      },
      "context": {
        "extra": {},
        "framework": null,
        "gpu_type": null,
        "gpus_per_node": null,
        "model": null,
        "network": null,
        "nic_count": null,
        "nodes": 1,
        "scale": "unknown",
        "topology": "unknown",
        "workload": "demo",
        "workload_kind": "workload"
      },
      "created_at": "2026-02-02T18:46:23.049644Z",
      "evidence": {
        "baseline_ms": 1084.0,
        "best_ms": 918.0,
        "history_count": 9,
        "improvement": 0.15313653136531366,
        "records": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8
        ]
      },
      "id": "427558ec-f07e-44f7-938e-c85da497a46f",
      "improvement": 0.15313653136531366,
      "last_used": null,
      "rule_type": "positive",
      "source": "online_tuning",
      "tries": 0,
      "wins": 0
    },
    {
      "confidence": 0.405,
      "config_patch": {
        "NCCL_ALGO": "TREE",
        "NCCL_NTHREADS": 192,
        "NCCL_PROTO": "LL"
      },
      "context": {
        "extra": {},
        "framework": null,
        "gpu_type": null,
        "gpus_per_node": null,
        "model": null,
        "network": null,
        "nic_count": null,
        "nodes": 1,
        "scale": "unknown",
        "topology": "unknown",
        "workload": "demo",
        "workload_kind": "workload"
      },
      "created_at": "2026-02-02T18:46:24.927906Z",
      "evidence": {},
      "id": "9e034b7e-4b7b-4d64-a515-aca360ae17c9",
      "improvement": 0.1492007104795737,
      "last_used": null,
      "rule_type": "positive",
      "source": "online_tuning",
      "tries": 0,
      "wins": 0
    },
    {
      "confidence": 0.405,
      "config_patch": {
        "NCCL_ALGO": "TREE",
        "NCCL_NTHREADS": 192,
        "NCCL_PROTO": "LL"
      },
      "context": {
        "extra": {},
        "framework": null,
        "gpu_type": null,
        "gpus_per_node": null,
        "model": null,
        "network": null,
        "nic_count": null,
        "nodes": 1,
        "scale": "unknown",
        "topology": "unknown",
        "workload": "demo",
        "workload_kind": "workload"
      },
      "created_at": "2026-02-02T18:46:24.928847Z",
      "evidence": {
        "baseline_ms": 1126.0,
        "best_ms": 958.0,
        "history_count": 8,
        "improvement": 0.1492007104795737,
        "records": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7
        ]
      },
      "id": "1597de9d-c1e2-41bf-a8fa-cd8cbd5e335f",
      "improvement": 0.1492007104795737,
      "last_used": null,
      "rule_type": "positive",
      "source": "online_tuning",
      "tries": 0,
      "wins": 0
    },
    {
      "confidence": 0.405,
      "config_patch": {
        "NCCL_ALGO": "TREE",
        "NCCL_NTHREADS": 192,
        "NCCL_PROTO": "LL"
      },
      "context": {
        "extra": {},
        "framework": null,
        "gpu_type": null,
        "gpus_per_node": null,
        "model": null,
        "network": null,
        "nic_count": null,
        "nodes": 1,
        "scale": "unknown",
        "topology": "unknown",
        "workload": "demo",
        "workload_kind": "workload"
      },
      "created_at": "2026-02-02T18:46:26.355131Z",
      "evidence": {},
      "id": "904bef8a-a50e-4ad7-b569-f9d4aaea5824",
      "improvement": 0.1492007104795737,
      "last_used": null,
      "rule_type": "positive",
      "source": "online_tuning",
      "tries": 0,
      "wins": 0
    },
    {
      "confidence": 0.405,
      "config_patch": {
        "NCCL_ALGO": "TREE",
        "NCCL_NTHREADS": 192,
        "NCCL_PROTO": "LL"
      },
      "context": {
        "extra": {},
        "framework": null,
        "gpu_type": null,
        "gpus_per_node": null,
        "model": null,
        "network": null,
        "nic_count": null,
        "nodes": 1,
        "scale": "unknown",
        "topology": "unknown",
        "workload": "demo",
        "workload_kind": "workload"
      },
      "created_at": "2026-02-02T18:46:26.355911Z",
      "evidence": {
        "baseline_ms": 1126.0,
        "best_ms": 958.0,
        "history_count": 8,
        "improvement": 0.1492007104795737,
        "records": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7
        ]
      },
      "id": "7a246c9d-8ab2-4879-9e80-1f396392aa78",
      "improvement": 0.1492007104795737,
      "last_used": null,
      "rule_type": "positive",
      "source": "online_tuning",
      "tries": 0,
      "wins": 0
    },
    {
      "confidence": 0.405,
      "config_patch": {
        "NCCL_ALGO": "TREE",
        "NCCL_NTHREADS": 192,
        "NCCL_PROTO": "LL"
      },
      "context": {
        "extra": {},
        "framework": null,
        "gpu_type": null,
        "gpus_per_node": null,
        "model": null,
        "network": null,
        "nic_count": null,
        "nodes": 1,
        "scale": "unknown",
        "topology": "unknown",
        "workload": "demo",
        "workload_kind": "workload"
      },
      "created_at": "2026-02-02T18:46:28.791183Z",
      "evidence": {},
      "id": "f695f628-cb8a-4b82-bf1b-256aa99ee24c",
      "improvement": 0.1492007104795737,
      "last_used": null,
      "rule_type": "positive",
      "source": "online_tuning",
      "tries": 0,
      "wins": 0
    },
    {
      "confidence": 0.405,
      "config_patch": {
        "NCCL_ALGO": "TREE",
        "NCCL_NTHREADS": 192,
        "NCCL_PROTO": "LL"
      },
      "context": {
        "extra": {},
        "framework": null,
        "gpu_type": null,
        "gpus_per_node": null,
        "model": null,
        "network": null,
        "nic_count": null,
        "nodes": 1,
        "scale": "unknown",
        "topology": "unknown",
        "workload": "demo",
        "workload_kind": "workload"
      },
      "created_at": "2026-02-02T18:46:28.791994Z",
      "evidence": {
        "baseline_ms": 1126.0,
        "best_ms": 958.0,
        "history_count": 8,
        "improvement": 0.1492007104795737,
        "records": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7
        ]
      },
      "id": "c0e3da05-b80c-45b4-88d2-9d6eaaf2af15",
      "improvement": 0.1492007104795737,
      "last_used": null,
      "rule_type": "positive",
      "source": "online_tuning",
      "tries": 0,
      "wins": 0
    },
    {
      "confidence": 0.405,
      "config_patch": {
        "NCCL_ALGO": "TREE",
        "NCCL_NTHREADS": 192,
        "NCCL_PROTO": "LL"
      },
      "context": {
        "extra": {},
        "framework": null,
        "gpu_type": null,
        "gpus_per_node": null,
        "model": null,
        "network": null,
        "nic_count": null,
        "nodes": 1,
        "scale": "unknown",
        "topology": "unknown",
        "workload": "demo",
        "workload_kind": "workload"
      },
      "created_at": "2026-02-02T18:46:52.630465Z",
      "evidence": {},
      "id": "1ae4d38d-73ff-4bab-9ff8-bbc950f5e608",
      "improvement": 0.1492007104795737,
      "last_used": null,
      "rule_type": "positive",
      "source": "online_tuning",
      "tries": 0,
      "wins": 0
    },
    {
      "confidence": 0.405,
      "config_patch": {
        "NCCL_ALGO": "TREE",
        "NCCL_NTHREADS": 192,
        "NCCL_PROTO": "LL"
      },
      "context": {
        "extra": {},
        "framework": null,
        "gpu_type": null,
        "gpus_per_node": null,
        "model": null,
        "network": null,
        "nic_count": null,
        "nodes": 1,
        "scale": "unknown",
        "topology": "unknown",
        "workload": "demo",
        "workload_kind": "workload"
      },
      "created_at": "2026-02-02T18:46:52.631337Z",
      "evidence": {
        "baseline_ms": 1126.0,
        "best_ms": 958.0,
        "history_count": 8,
        "improvement": 0.1492007104795737,
        "records": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7
        ]
      },
      "id": "cf43c372-e543-40ea-9cba-aa070cb03c9b",
      "improvement": 0.1492007104795737,
      "last_used": null,
      "rule_type": "positive",
      "source": "online_tuning",
      "tries": 0,
      "wins": 0
    },
    {
      "confidence": 0.2657205000000001,
      "config_patch": {
        "NCCL_ALGO": "TREE",
        "NCCL_NTHREADS": 192,
        "NCCL_PROTO": "LL"
      },
      "context": {
        "extra": {
          "category": "llm",
          "cluster": "4-node, 32xA40, PCIe intra, 100Gbps IB",
          "collectives": [
            "AllGather",
            "ReduceScatter",
            "AllReduce"
          ],
          "framework": "PyTorch + Megatron-LM",
          "model": "Phi-2-2B",
          "parallelism": "TP(8)+DP(4)",
          "source": "AutoCCL NSDI'25 evaluation"
        },
        "framework": "PyTorch + Megatron-LM",
        "gpu_type": null,
        "gpus_per_node": null,
        "model": "Phi-2-2B",
        "network": null,
        "nic_count": null,
        "nodes": 4,
        "scale": "32-gpu",
        "topology": "a40-pcie-8gpu",
        "workload": "autoccl-phi2-2b",
        "workload_kind": "training"
      },
      "created_at": "2026-02-02T18:47:35.803530Z",
      "evidence": {},
      "id": "ec8f488b-49c9-45de-b366-77592a2aecf2",
      "improvement": 0.16236162361623616,
      "last_used": null,
      "rule_type": "positive",
      "source": "online_tuning",
      "tries": 0,
      "wins": 0
    },
    {
      "confidence": 0.2657205000000001,
      "config_patch": {
        "NCCL_ALGO": "TREE",
        "NCCL_NTHREADS": 192,
        "NCCL_PROTO": "LL"
      },
      "context": {
        "extra": {
          "category": "llm",
          "cluster": "4-node, 32xA40, PCIe intra, 100Gbps IB",
          "collectives": [
            "AllGather",
            "ReduceScatter",
            "AllReduce"
          ],
          "framework": "PyTorch + Megatron-LM",
          "model": "Phi-2-2B",
          "parallelism": "TP(8)+DP(4)",
          "source": "AutoCCL NSDI'25 evaluation"
        },
        "framework": "PyTorch + Megatron-LM",
        "gpu_type": null,
        "gpus_per_node": null,
        "model": "Phi-2-2B",
        "network": null,
        "nic_count": null,
        "nodes": 4,
        "scale": "32-gpu",
        "topology": "a40-pcie-8gpu",
        "workload": "autoccl-phi2-2b",
        "workload_kind": "training"
      },
      "created_at": "2026-02-02T18:47:35.804533Z",
      "evidence": {
        "baseline_ms": 1355.0,
        "best_ms": 1135.0,
        "history_count": 7,
        "improvement": 0.16236162361623616,
        "records": [
          0,
          1,
          2,
          3,
          4,
          5,
          6
        ]
      },
      "id": "b8cc4e5c-e9ed-454a-a7ed-3c99a17e2ea3",
      "improvement": 0.16236162361623616,
      "last_used": null,
      "rule_type": "positive",
      "source": "online_tuning",
      "tries": 0,
      "wins": 0
    },
    {
      "confidence": 0.21523360500000008,
      "config_patch": {
        "NCCL_BUFFSIZE": 2097152
      },
      "context": {
        "extra": {
          "category": "llm",
          "cluster": "4-node, 32xA40, PCIe intra, 100Gbps IB",
          "collectives": [
            "AllGather",
            "ReduceScatter",
            "AllReduce"
          ],
          "framework": "PyTorch + Megatron-LM",
          "model": "Phi-2-2B",
          "parallelism": "TP(8)+DP(4)",
          "source": "AutoCCL NSDI'25 evaluation"
        },
        "framework": "PyTorch + Megatron-LM",
        "gpu_type": null,
        "gpus_per_node": null,
        "model": "Phi-2-2B",
        "network": null,
        "nic_count": null,
        "nodes": 4,
        "scale": "32-gpu",
        "topology": "a40-pcie-8gpu",
        "workload": "autoccl-phi2-2b",
        "workload_kind": "training"
      },
      "created_at": "2026-02-02T18:48:02.843075Z",
      "evidence": {},
      "id": "748d2652-db09-4c07-b193-c97cee4b86a7",
      "improvement": 0.18042226487523993,
      "last_used": null,
      "rule_type": "positive",
      "source": "online_tuning",
      "tries": 0,
      "wins": 0
    },
    {
      "confidence": 0.21523360500000008,
      "config_patch": {
        "NCCL_BUFFSIZE": 2097152
      },
      "context": {
        "extra": {
          "category": "llm",
          "cluster": "4-node, 32xA40, PCIe intra, 100Gbps IB",
          "collectives": [
            "AllGather",
            "ReduceScatter",
            "AllReduce"
          ],
          "framework": "PyTorch + Megatron-LM",
          "model": "Phi-2-2B",
          "parallelism": "TP(8)+DP(4)",
          "source": "AutoCCL NSDI'25 evaluation"
        },
        "framework": "PyTorch + Megatron-LM",
        "gpu_type": null,
        "gpus_per_node": null,
        "model": "Phi-2-2B",
        "network": null,
        "nic_count": null,
        "nodes": 4,
        "scale": "32-gpu",
        "topology": "a40-pcie-8gpu",
        "workload": "autoccl-phi2-2b",
        "workload_kind": "training"
      },
      "created_at": "2026-02-02T18:48:02.844089Z",
      "evidence": {
        "baseline_ms": 1302.5,
        "best_ms": 1067.5,
        "history_count": 9,
        "improvement": 0.18042226487523993,
        "records": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8
        ]
      },
      "id": "d4e13666-68ec-4ac3-89a0-4d5bb26a3652",
      "improvement": 0.18042226487523993,
      "last_used": null,
      "rule_type": "positive",
      "source": "online_tuning",
      "tries": 0,
      "wins": 0
    },
    {
      "confidence": 0.2657205000000001,
      "config_patch": {
        "NCCL_ALGO": "TREE",
        "NCCL_NTHREADS": 192,
        "NCCL_PROTO": "LL"
      },
      "context": {
        "extra": {
          "category": "llm",
          "cluster": "4-node, 32xA40, PCIe intra, 100Gbps IB",
          "collectives": [
            "AllGather",
            "ReduceScatter",
            "AllReduce"
          ],
          "framework": "PyTorch + Megatron-LM",
          "model": "Phi-2-2B",
          "parallelism": "TP(8)+DP(4)",
          "source": "AutoCCL NSDI'25 evaluation"
        },
        "framework": "PyTorch + Megatron-LM",
        "gpu_type": null,
        "gpus_per_node": null,
        "model": "Phi-2-2B",
        "network": null,
        "nic_count": null,
        "nodes": 4,
        "scale": "32-gpu",
        "topology": "a40-pcie-8gpu",
        "workload": "autoccl-phi2-2b",
        "workload_kind": "training"
      },
      "created_at": "2026-02-02T18:48:04.542803Z",
      "evidence": {},
      "id": "7537d3ed-dafa-4ab9-b11d-f0e9ecbf44cb",
      "improvement": 0.20738137082601055,
      "last_used": null,
      "rule_type": "positive",
      "source": "online_tuning",
      "tries": 0,
      "wins": 0
    },
    {
      "confidence": 0.2657205000000001,
      "config_patch": {
        "NCCL_ALGO": "TREE",
        "NCCL_NTHREADS": 192,
        "NCCL_PROTO": "LL"
      },
      "context": {
        "extra": {
          "category": "llm",
          "cluster": "4-node, 32xA40, PCIe intra, 100Gbps IB",
          "collectives": [
            "AllGather",
            "ReduceScatter",
            "AllReduce"
          ],
          "framework": "PyTorch + Megatron-LM",
          "model": "Phi-2-2B",
          "parallelism": "TP(8)+DP(4)",
          "source": "AutoCCL NSDI'25 evaluation"
        },
        "framework": "PyTorch + Megatron-LM",
        "gpu_type": null,
        "gpus_per_node": null,
        "model": "Phi-2-2B",
        "network": null,
        "nic_count": null,
        "nodes": 4,
        "scale": "32-gpu",
        "topology": "a40-pcie-8gpu",
        "workload": "autoccl-phi2-2b",
        "workload_kind": "training"
      },
      "created_at": "2026-02-02T18:48:04.543975Z",
      "evidence": {
        "baseline_ms": 1422.5,
        "best_ms": 1127.5,
        "history_count": 8,
        "improvement": 0.20738137082601055,
        "records": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7
        ]
      },
      "id": "3b803208-9ef2-48ac-9658-9ef4ab417613",
      "improvement": 0.20738137082601055,
      "last_used": null,
      "rule_type": "positive",
      "source": "online_tuning",
      "tries": 0,
      "wins": 0
    },
    {
      "confidence": 0.17433922005000008,
      "config_patch": {
        "NCCL_BUFFSIZE": 5242880,
        "NCCL_NTHREADS": 256,
        "NCCL_PROTO": "LL128"
      },
      "context": {
        "extra": {
          "category": "llm",
          "cluster": "4-node, 32xA40, PCIe intra, 100Gbps IB",
          "collectives": [
            "AllGather",
            "ReduceScatter",
            "AllReduce"
          ],
          "framework": "PyTorch + Megatron-LM",
          "model": "Phi-2-2B",
          "parallelism": "TP(8)+DP(4)",
          "source": "AutoCCL NSDI'25 evaluation"
        },
        "framework": "PyTorch + Megatron-LM",
        "gpu_type": null,
        "gpus_per_node": null,
        "model": "Phi-2-2B",
        "network": null,
        "nic_count": null,
        "nodes": 4,
        "scale": "32-gpu",
        "topology": "a40-pcie-8gpu",
        "workload": "autoccl-phi2-2b",
        "workload_kind": "training"
      },
      "created_at": "2026-02-02T18:48:05.711710Z",
      "evidence": {},
      "id": "0e4c207e-1912-4b9a-af10-40d4c34eb62e",
      "improvement": 0.12092130518234183,
      "last_used": null,
      "rule_type": "positive",
      "source": "online_tuning",
      "tries": 0,
      "wins": 0
    },
    {
      "confidence": 0.17433922005000008,
      "config_patch": {
        "NCCL_BUFFSIZE": 5242880,
        "NCCL_NTHREADS": 256,
        "NCCL_PROTO": "LL128"
      },
      "context": {
        "extra": {
          "category": "llm",
          "cluster": "4-node, 32xA40, PCIe intra, 100Gbps IB",
          "collectives": [
            "AllGather",
            "ReduceScatter",
            "AllReduce"
          ],
          "framework": "PyTorch + Megatron-LM",
          "model": "Phi-2-2B",
          "parallelism": "TP(8)+DP(4)",
          "source": "AutoCCL NSDI'25 evaluation"
        },
        "framework": "PyTorch + Megatron-LM",
        "gpu_type": null,
        "gpus_per_node": null,
        "model": "Phi-2-2B",
        "network": null,
        "nic_count": null,
        "nodes": 4,
        "scale": "32-gpu",
        "topology": "a40-pcie-8gpu",
        "workload": "autoccl-phi2-2b",
        "workload_kind": "training"
      },
      "created_at": "2026-02-02T18:48:05.712860Z",
      "evidence": {
        "baseline_ms": 1302.5,
        "best_ms": 1144.9999999999998,
        "history_count": 9,
        "improvement": 0.12092130518234183,
        "records": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8
        ]
      },
      "id": "1a81ef32-1870-42da-9b36-e7d7d51facc5",
      "improvement": 0.12092130518234183,
      "last_used": null,
      "rule_type": "positive",
      "source": "online_tuning",
      "tries": 0,
      "wins": 0
    },
    {
      "confidence": 0.21523360500000008,
      "config_patch": {
        "NCCL_BUFFSIZE": 1048576
      },
      "context": {
        "extra": {
          "category": "llm",
          "cluster": "4-node, 32xA40, PCIe intra, 100Gbps IB",
          "collectives": [
            "AllGather",
            "ReduceScatter",
            "AllReduce"
          ],
          "framework": "PyTorch + Megatron-LM",
          "model": "Phi-2-2B",
          "parallelism": "TP(8)+DP(4)",
          "source": "AutoCCL NSDI'25 evaluation"
        },
        "framework": "PyTorch + Megatron-LM",
        "gpu_type": null,
        "gpus_per_node": null,
        "model": "Phi-2-2B",
        "network": null,
        "nic_count": null,
        "nodes": 4,
        "scale": "32-gpu",
        "topology": "a40-pcie-8gpu",
        "workload": "autoccl-phi2-2b",
        "workload_kind": "training"
      },
      "created_at": "2026-02-02T18:56:14.188572Z",
      "evidence": {},
      "id": "6bf47f84-6777-46c8-a3a3-8e86f756a457",
      "improvement": 0.029473684210526315,
      "last_used": null,
      "rule_type": "positive",
      "source": "online_tuning",
      "tries": 0,
      "wins": 0
    },
    {
      "confidence": 0.21523360500000008,
      "config_patch": {
        "NCCL_BUFFSIZE": 1048576
      },
      "context": {
        "extra": {
          "category": "llm",
          "cluster": "4-node, 32xA40, PCIe intra, 100Gbps IB",
          "collectives": [
            "AllGather",
            "ReduceScatter",
            "AllReduce"
          ],
          "framework": "PyTorch + Megatron-LM",
          "model": "Phi-2-2B",
          "parallelism": "TP(8)+DP(4)",
          "source": "AutoCCL NSDI'25 evaluation"
        },
        "framework": "PyTorch + Megatron-LM",
        "gpu_type": null,
        "gpus_per_node": null,
        "model": "Phi-2-2B",
        "network": null,
        "nic_count": null,
        "nodes": 4,
        "scale": "32-gpu",
        "topology": "a40-pcie-8gpu",
        "workload": "autoccl-phi2-2b",
        "workload_kind": "training"
      },
      "created_at": "2026-02-02T18:56:14.190389Z",
      "evidence": {
        "baseline_ms": 1187.5,
        "best_ms": 1152.5,
        "history_count": 6,
        "improvement": 0.029473684210526315,
        "records": [
          0,
          1,
          2,
          3,
          4,
          5
        ]
      },
      "id": "1b633577-47be-49a2-a4eb-eebfe34670dd",
      "improvement": 0.029473684210526315,
      "last_used": null,
      "rule_type": "positive",
      "source": "online_tuning",
      "tries": 0,
      "wins": 0
    },
    {
      "confidence": 0.21523360500000008,
      "config_patch": {
        "NCCL_BUFFSIZE": 6291456
      },
      "context": {
        "extra": {
          "category": "llm",
          "cluster": "4-node, 32xA40, PCIe intra, 100Gbps IB",
          "collectives": [
            "AllGather",
            "ReduceScatter",
            "AllReduce"
          ],
          "framework": "PyTorch + Megatron-LM",
          "model": "Phi-2-2B",
          "parallelism": "TP(8)+DP(4)",
          "source": "AutoCCL NSDI'25 evaluation"
        },
        "framework": "PyTorch + Megatron-LM",
        "gpu_type": null,
        "gpus_per_node": null,
        "model": "Phi-2-2B",
        "network": null,
        "nic_count": null,
        "nodes": 4,
        "scale": "32-gpu",
        "topology": "a40-pcie-8gpu",
        "workload": "autoccl-phi2-2b",
        "workload_kind": "training"
      },
      "created_at": "2026-02-02T18:56:35.620877Z",
      "evidence": {},
      "id": "39f1f917-8610-44bd-968d-355d76847615",
      "improvement": 0.1746641074856046,
      "last_used": null,
      "rule_type": "positive",
      "source": "online_tuning",
      "tries": 0,
      "wins": 0
    },
    {
      "confidence": 0.21523360500000008,
      "config_patch": {
        "NCCL_BUFFSIZE": 6291456
      },
      "context": {
        "extra": {
          "category": "llm",
          "cluster": "4-node, 32xA40, PCIe intra, 100Gbps IB",
          "collectives": [
            "AllGather",
            "ReduceScatter",
            "AllReduce"
          ],
          "framework": "PyTorch + Megatron-LM",
          "model": "Phi-2-2B",
          "parallelism": "TP(8)+DP(4)",
          "source": "AutoCCL NSDI'25 evaluation"
        },
        "framework": "PyTorch + Megatron-LM",
        "gpu_type": null,
        "gpus_per_node": null,
        "model": "Phi-2-2B",
        "network": null,
        "nic_count": null,
        "nodes": 4,
        "scale": "32-gpu",
        "topology": "a40-pcie-8gpu",
        "workload": "autoccl-phi2-2b",
        "workload_kind": "training"
      },
      "created_at": "2026-02-02T18:56:35.622734Z",
      "evidence": {
        "baseline_ms": 1302.5,
        "best_ms": 1075.0,
        "history_count": 9,
        "improvement": 0.1746641074856046,
        "records": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8
        ]
      },
      "id": "17be5757-2525-445c-b934-ca016b528321",
      "improvement": 0.1746641074856046,
      "last_used": null,
      "rule_type": "positive",
      "source": "online_tuning",
      "tries": 0,
      "wins": 0
    },
    {
      "confidence": 0.17433922005000008,
      "config_patch": {
        "NCCL_BUFFSIZE": 5242880,
        "NCCL_NTHREADS": 256,
        "NCCL_PROTO": "LL128"
      },
      "context": {
        "extra": {
          "category": "llm",
          "cluster": "4-node, 32xA40, PCIe intra, 100Gbps IB",
          "collectives": [
            "AllGather",
            "ReduceScatter",
            "AllReduce"
          ],
          "framework": "PyTorch + Megatron-LM",
          "model": "Phi-2-2B",
          "parallelism": "TP(8)+DP(4)",
          "source": "AutoCCL NSDI'25 evaluation"
        },
        "framework": "PyTorch + Megatron-LM",
        "gpu_type": null,
        "gpus_per_node": null,
        "model": "Phi-2-2B",
        "network": null,
        "nic_count": null,
        "nodes": 4,
        "scale": "32-gpu",
        "topology": "a40-pcie-8gpu",
        "workload": "autoccl-phi2-2b",
        "workload_kind": "training"
      },
      "created_at": "2026-02-02T18:58:59.353592Z",
      "evidence": {},
      "id": "357622d6-e17c-4836-8df0-c9895bbef41e",
      "improvement": 0.12092130518234183,
      "last_used": null,
      "rule_type": "positive",
      "source": "online_tuning",
      "tries": 0,
      "wins": 0
    },
    {
      "confidence": 0.17433922005000008,
      "config_patch": {
        "NCCL_BUFFSIZE": 5242880,
        "NCCL_NTHREADS": 256,
        "NCCL_PROTO": "LL128"
      },
      "context": {
        "extra": {
          "category": "llm",
          "cluster": "4-node, 32xA40, PCIe intra, 100Gbps IB",
          "collectives": [
            "AllGather",
            "ReduceScatter",
            "AllReduce"
          ],
          "framework": "PyTorch + Megatron-LM",
          "model": "Phi-2-2B",
          "parallelism": "TP(8)+DP(4)",
          "source": "AutoCCL NSDI'25 evaluation"
        },
        "framework": "PyTorch + Megatron-LM",
        "gpu_type": null,
        "gpus_per_node": null,
        "model": "Phi-2-2B",
        "network": null,
        "nic_count": null,
        "nodes": 4,
        "scale": "32-gpu",
        "topology": "a40-pcie-8gpu",
        "workload": "autoccl-phi2-2b",
        "workload_kind": "training"
      },
      "created_at": "2026-02-02T18:58:59.355132Z",
      "evidence": {
        "baseline_ms": 1302.5,
        "best_ms": 1144.9999999999998,
        "history_count": 9,
        "improvement": 0.12092130518234183,
        "records": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8
        ]
      },
      "id": "2cf4ff38-71e1-4fc7-8d7d-d0e8b2ad3fb6",
      "improvement": 0.12092130518234183,
      "last_used": null,
      "rule_type": "positive",
      "source": "online_tuning",
      "tries": 0,
      "wins": 0
    },
    {
      "confidence": 0.32805000000000006,
      "config_patch": {
        "NCCL_NTHREADS": 256
      },
      "context": {
        "extra": {
          "category": "llm",
          "cluster": "4-node, 32xA40, PCIe intra, 100Gbps IB",
          "collectives": [
            "AllGather",
            "ReduceScatter",
            "AllReduce"
          ],
          "framework": "PyTorch + Megatron-LM",
          "model": "Phi-2-2B",
          "parallelism": "TP(8)+DP(4)",
          "source": "AutoCCL NSDI'25 evaluation"
        },
        "framework": "PyTorch + Megatron-LM",
        "gpu_type": null,
        "gpus_per_node": null,
        "model": "Phi-2-2B",
        "network": null,
        "nic_count": null,
        "nodes": 4,
        "scale": "32-gpu",
        "topology": "a40-pcie-8gpu",
        "workload": "autoccl-phi2-2b",
        "workload_kind": "training"
      },
      "created_at": "2026-02-02T19:01:05.228608Z",
      "evidence": {},
      "id": "f9f1195e-da23-4e19-ab33-40d004851bd3",
      "improvement": 0.07196969696969714,
      "last_used": null,
      "rule_type": "positive",
      "source": "online_tuning",
      "tries": 0,
      "wins": 0
    },
    {
      "confidence": 0.32805000000000006,
      "config_patch": {
        "NCCL_NTHREADS": 256
      },
      "context": {
        "extra": {
          "category": "llm",
          "cluster": "4-node, 32xA40, PCIe intra, 100Gbps IB",
          "collectives": [
            "AllGather",
            "ReduceScatter",
            "AllReduce"
          ],
          "framework": "PyTorch + Megatron-LM",
          "model": "Phi-2-2B",
          "parallelism": "TP(8)+DP(4)",
          "source": "AutoCCL NSDI'25 evaluation"
        },
        "framework": "PyTorch + Megatron-LM",
        "gpu_type": null,
        "gpus_per_node": null,
        "model": "Phi-2-2B",
        "network": null,
        "nic_count": null,
        "nodes": 4,
        "scale": "32-gpu",
        "topology": "a40-pcie-8gpu",
        "workload": "autoccl-phi2-2b",
        "workload_kind": "training"
      },
      "created_at": "2026-02-02T19:01:05.229965Z",
      "evidence": {
        "baseline_ms": 1320.0,
        "best_ms": 1224.9999999999998,
        "history_count": 5,
        "improvement": 0.07196969696969714,
        "records": [
          0,
          1,
          2,
          3,
          4
        ]
      },
      "id": "94b00adb-c674-46bf-a2d5-1465db85fba5",
      "improvement": 0.07196969696969714,
      "last_used": null,
      "rule_type": "positive",
      "source": "online_tuning",
      "tries": 0,
      "wins": 0
    }
  ],
  "schema_version": "2.0",
  "surrogates": [
    {
      "config": {
        "NCCL_ALGO": "RING",
        "NCCL_BUFFSIZE": 4194304,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 256,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "SIMPLE",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {},
        "framework": null,
        "gpu_type": null,
        "gpus_per_node": null,
        "model": null,
        "network": null,
        "nic_count": null,
        "nodes": 1,
        "scale": "unknown",
        "topology": "unknown",
        "workload": "demo",
        "workload_kind": "workload"
      },
      "created_at": "2026-02-02T16:59:39.813103Z",
      "metrics": {
        "algbw_gbps": 138.0,
        "busbw_gbps": 124.2,
        "comm_time_ms": 426.40000000000003,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 1066.0,
        "loss": null,
        "raw": {
          "seed": 12978238,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": 4194304,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 192,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {},
        "framework": null,
        "gpu_type": null,
        "gpus_per_node": null,
        "model": null,
        "network": null,
        "nic_count": null,
        "nodes": 1,
        "scale": "unknown",
        "topology": "unknown",
        "workload": "demo",
        "workload_kind": "workload"
      },
      "created_at": "2026-02-02T16:59:39.813115Z",
      "metrics": {
        "algbw_gbps": 147.0,
        "busbw_gbps": 132.3,
        "comm_time_ms": 429.6,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 1074.0,
        "loss": null,
        "raw": {
          "seed": 6306147,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "RING",
        "NCCL_BUFFSIZE": 4194304,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 192,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {},
        "framework": null,
        "gpu_type": null,
        "gpus_per_node": null,
        "model": null,
        "network": null,
        "nic_count": null,
        "nodes": 1,
        "scale": "unknown",
        "topology": "unknown",
        "workload": "demo",
        "workload_kind": "workload"
      },
      "created_at": "2026-02-02T16:59:39.813126Z",
      "metrics": {
        "algbw_gbps": 109.0,
        "busbw_gbps": 98.10000000000001,
        "comm_time_ms": 435.2,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 1087.9999999999998,
        "loss": null,
        "raw": {
          "seed": 389859,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": 5242880,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 192,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {},
        "framework": null,
        "gpu_type": null,
        "gpus_per_node": null,
        "model": null,
        "network": null,
        "nic_count": null,
        "nodes": 1,
        "scale": "unknown",
        "topology": "unknown",
        "workload": "demo",
        "workload_kind": "workload"
      },
      "created_at": "2026-02-02T16:59:39.813212Z",
      "metrics": {
        "algbw_gbps": 145.0,
        "busbw_gbps": 130.5,
        "comm_time_ms": 420.00000000000006,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 1050.0,
        "loss": null,
        "raw": {
          "seed": 8654045,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "RING",
        "NCCL_BUFFSIZE": 5242880,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 192,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {},
        "framework": null,
        "gpu_type": null,
        "gpus_per_node": null,
        "model": null,
        "network": null,
        "nic_count": null,
        "nodes": 1,
        "scale": "unknown",
        "topology": "unknown",
        "workload": "demo",
        "workload_kind": "workload"
      },
      "created_at": "2026-02-02T16:59:39.813233Z",
      "metrics": {
        "algbw_gbps": 146.0,
        "busbw_gbps": 131.4,
        "comm_time_ms": 456.8,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 1142.0,
        "loss": null,
        "raw": {
          "seed": 4700196,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": 5242880,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 256,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL128",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {},
        "framework": null,
        "gpu_type": null,
        "gpus_per_node": null,
        "model": null,
        "network": null,
        "nic_count": null,
        "nodes": 1,
        "scale": "unknown",
        "topology": "unknown",
        "workload": "demo",
        "workload_kind": "workload"
      },
      "created_at": "2026-02-02T16:59:39.813244Z",
      "metrics": {
        "algbw_gbps": 114.0,
        "busbw_gbps": 102.60000000000001,
        "comm_time_ms": 387.2,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 968.0,
        "loss": null,
        "raw": {
          "seed": 15787014,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "RING",
        "NCCL_BUFFSIZE": 5242880,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 256,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL128",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {},
        "framework": null,
        "gpu_type": null,
        "gpus_per_node": null,
        "model": null,
        "network": null,
        "nic_count": null,
        "nodes": 1,
        "scale": "unknown",
        "topology": "unknown",
        "workload": "demo",
        "workload_kind": "workload"
      },
      "created_at": "2026-02-02T16:59:39.813254Z",
      "metrics": {
        "algbw_gbps": 108.0,
        "busbw_gbps": 97.2,
        "comm_time_ms": 418.40000000000003,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 1046.0,
        "loss": null,
        "raw": {
          "seed": 10316158,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": 6291456,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 256,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL128",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {},
        "framework": null,
        "gpu_type": null,
        "gpus_per_node": null,
        "model": null,
        "network": null,
        "nic_count": null,
        "nodes": 1,
        "scale": "unknown",
        "topology": "unknown",
        "workload": "demo",
        "workload_kind": "workload"
      },
      "created_at": "2026-02-02T16:59:39.813263Z",
      "metrics": {
        "algbw_gbps": 131.0,
        "busbw_gbps": 117.9,
        "comm_time_ms": 432.79999999999995,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 1081.9999999999998,
        "loss": null,
        "raw": {
          "seed": 1030381,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "RING",
        "NCCL_BUFFSIZE": 6291456,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 256,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL128",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {},
        "framework": null,
        "gpu_type": null,
        "gpus_per_node": null,
        "model": null,
        "network": null,
        "nic_count": null,
        "nodes": 1,
        "scale": "unknown",
        "topology": "unknown",
        "workload": "demo",
        "workload_kind": "workload"
      },
      "created_at": "2026-02-02T16:59:39.813273Z",
      "metrics": {
        "algbw_gbps": 126.0,
        "busbw_gbps": 113.4,
        "comm_time_ms": 384.8,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 962.0000000000001,
        "loss": null,
        "raw": {
          "seed": 3282626,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "RING",
        "NCCL_BUFFSIZE": 6291456,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 256,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL128",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {},
        "framework": null,
        "gpu_type": null,
        "gpus_per_node": null,
        "model": null,
        "network": null,
        "nic_count": null,
        "nodes": 1,
        "scale": "unknown",
        "topology": "unknown",
        "workload": "demo",
        "workload_kind": "workload"
      },
      "created_at": "2026-02-02T18:46:17.591135Z",
      "metrics": {
        "algbw_gbps": 126.0,
        "busbw_gbps": 113.4,
        "comm_time_ms": 416.80000000000007,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 1042.0,
        "loss": null,
        "raw": {
          "seed": 3282626,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": 6291456,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 192,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {},
        "framework": null,
        "gpu_type": null,
        "gpus_per_node": null,
        "model": null,
        "network": null,
        "nic_count": null,
        "nodes": 1,
        "scale": "unknown",
        "topology": "unknown",
        "workload": "demo",
        "workload_kind": "workload"
      },
      "created_at": "2026-02-02T18:46:17.591147Z",
      "metrics": {
        "algbw_gbps": 104.0,
        "busbw_gbps": 93.60000000000001,
        "comm_time_ms": 395.2,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 988.0,
        "loss": null,
        "raw": {
          "seed": 8993604,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": 6291456,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 192,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL128",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {},
        "framework": null,
        "gpu_type": null,
        "gpus_per_node": null,
        "model": null,
        "network": null,
        "nic_count": null,
        "nodes": 1,
        "scale": "unknown",
        "topology": "unknown",
        "workload": "demo",
        "workload_kind": "workload"
      },
      "created_at": "2026-02-02T18:46:17.591158Z",
      "metrics": {
        "algbw_gbps": 143.0,
        "busbw_gbps": 128.70000000000002,
        "comm_time_ms": 422.40000000000003,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 1056.0,
        "loss": null,
        "raw": {
          "seed": 193043,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": 5242880,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 192,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {},
        "framework": null,
        "gpu_type": null,
        "gpus_per_node": null,
        "model": null,
        "network": null,
        "nic_count": null,
        "nodes": 1,
        "scale": "unknown",
        "topology": "unknown",
        "workload": "demo",
        "workload_kind": "workload"
      },
      "created_at": "2026-02-02T18:46:17.591169Z",
      "metrics": {
        "algbw_gbps": 145.0,
        "busbw_gbps": 130.5,
        "comm_time_ms": 420.00000000000006,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 1050.0,
        "loss": null,
        "raw": {
          "seed": 8654045,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": 6291456,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 192,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL128",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {},
        "framework": null,
        "gpu_type": null,
        "gpus_per_node": null,
        "model": null,
        "network": null,
        "nic_count": null,
        "nodes": 1,
        "scale": "unknown",
        "topology": "unknown",
        "workload": "demo",
        "workload_kind": "workload"
      },
      "created_at": "2026-02-02T18:46:17.591182Z",
      "metrics": {
        "algbw_gbps": 143.0,
        "busbw_gbps": 128.70000000000002,
        "comm_time_ms": 414.40000000000003,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 1036.0,
        "loss": null,
        "raw": {
          "seed": 193043,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": 4194304,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 192,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {},
        "framework": null,
        "gpu_type": null,
        "gpus_per_node": null,
        "model": null,
        "network": null,
        "nic_count": null,
        "nodes": 1,
        "scale": "unknown",
        "topology": "unknown",
        "workload": "demo",
        "workload_kind": "workload"
      },
      "created_at": "2026-02-02T18:46:23.048790Z",
      "metrics": {
        "algbw_gbps": 147.0,
        "busbw_gbps": 132.3,
        "comm_time_ms": 433.6,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 1084.0,
        "loss": null,
        "raw": {
          "seed": 6306147,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": 4194304,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 256,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {},
        "framework": null,
        "gpu_type": null,
        "gpus_per_node": null,
        "model": null,
        "network": null,
        "nic_count": null,
        "nodes": 1,
        "scale": "unknown",
        "topology": "unknown",
        "workload": "demo",
        "workload_kind": "workload"
      },
      "created_at": "2026-02-02T18:46:23.048802Z",
      "metrics": {
        "algbw_gbps": 140.0,
        "busbw_gbps": 126.0,
        "comm_time_ms": 463.99999999999994,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 1160.0,
        "loss": null,
        "raw": {
          "seed": 3367090,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": 4194304,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 192,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {},
        "framework": null,
        "gpu_type": null,
        "gpus_per_node": null,
        "model": null,
        "network": null,
        "nic_count": null,
        "nodes": 1,
        "scale": "unknown",
        "topology": "unknown",
        "workload": "demo",
        "workload_kind": "workload"
      },
      "created_at": "2026-02-02T18:46:23.048819Z",
      "metrics": {
        "algbw_gbps": 147.0,
        "busbw_gbps": 132.3,
        "comm_time_ms": 425.6,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 1064.0,
        "loss": null,
        "raw": {
          "seed": 6306147,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": 5242880,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 192,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {},
        "framework": null,
        "gpu_type": null,
        "gpus_per_node": null,
        "model": null,
        "network": null,
        "nic_count": null,
        "nodes": 1,
        "scale": "unknown",
        "topology": "unknown",
        "workload": "demo",
        "workload_kind": "workload"
      },
      "created_at": "2026-02-02T18:46:23.048830Z",
      "metrics": {
        "algbw_gbps": 145.0,
        "busbw_gbps": 130.5,
        "comm_time_ms": 420.00000000000006,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 1050.0,
        "loss": null,
        "raw": {
          "seed": 8654045,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": 5242880,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 192,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {},
        "framework": null,
        "gpu_type": null,
        "gpus_per_node": null,
        "model": null,
        "network": null,
        "nic_count": null,
        "nodes": 1,
        "scale": "unknown",
        "topology": "unknown",
        "workload": "demo",
        "workload_kind": "workload"
      },
      "created_at": "2026-02-02T18:46:23.048841Z",
      "metrics": {
        "algbw_gbps": 145.0,
        "busbw_gbps": 130.5,
        "comm_time_ms": 416.00000000000006,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 1040.0,
        "loss": null,
        "raw": {
          "seed": 8654045,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": 5242880,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 256,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL128",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {},
        "framework": null,
        "gpu_type": null,
        "gpus_per_node": null,
        "model": null,
        "network": null,
        "nic_count": null,
        "nodes": 1,
        "scale": "unknown",
        "topology": "unknown",
        "workload": "demo",
        "workload_kind": "workload"
      },
      "created_at": "2026-02-02T18:46:23.048852Z",
      "metrics": {
        "algbw_gbps": 114.0,
        "busbw_gbps": 102.60000000000001,
        "comm_time_ms": 387.2,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 968.0,
        "loss": null,
        "raw": {
          "seed": 15787014,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": 5242880,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 192,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {},
        "framework": null,
        "gpu_type": null,
        "gpus_per_node": null,
        "model": null,
        "network": null,
        "nic_count": null,
        "nodes": 1,
        "scale": "unknown",
        "topology": "unknown",
        "workload": "demo",
        "workload_kind": "workload"
      },
      "created_at": "2026-02-02T18:46:23.048863Z",
      "metrics": {
        "algbw_gbps": 145.0,
        "busbw_gbps": 130.5,
        "comm_time_ms": 408.00000000000006,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 1020.0,
        "loss": null,
        "raw": {
          "seed": 8654045,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": 6291456,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 192,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL128",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {},
        "framework": null,
        "gpu_type": null,
        "gpus_per_node": null,
        "model": null,
        "network": null,
        "nic_count": null,
        "nodes": 1,
        "scale": "unknown",
        "topology": "unknown",
        "workload": "demo",
        "workload_kind": "workload"
      },
      "created_at": "2026-02-02T18:46:23.048874Z",
      "metrics": {
        "algbw_gbps": 143.0,
        "busbw_gbps": 128.70000000000002,
        "comm_time_ms": 402.40000000000003,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 1006.0,
        "loss": null,
        "raw": {
          "seed": 193043,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": 6291456,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 192,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {},
        "framework": null,
        "gpu_type": null,
        "gpus_per_node": null,
        "model": null,
        "network": null,
        "nic_count": null,
        "nodes": 1,
        "scale": "unknown",
        "topology": "unknown",
        "workload": "demo",
        "workload_kind": "workload"
      },
      "created_at": "2026-02-02T18:46:23.048885Z",
      "metrics": {
        "algbw_gbps": 104.0,
        "busbw_gbps": 93.60000000000001,
        "comm_time_ms": 367.20000000000005,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 918.0,
        "loss": null,
        "raw": {
          "seed": 8993604,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "RING",
        "NCCL_BUFFSIZE": 6291456,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 256,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "SIMPLE",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {},
        "framework": null,
        "gpu_type": null,
        "gpus_per_node": null,
        "model": null,
        "network": null,
        "nic_count": null,
        "nodes": 1,
        "scale": "unknown",
        "topology": "unknown",
        "workload": "demo",
        "workload_kind": "workload"
      },
      "created_at": "2026-02-02T18:46:24.927945Z",
      "metrics": {
        "algbw_gbps": 118.0,
        "busbw_gbps": 106.2,
        "comm_time_ms": 450.4000000000001,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 1126.0,
        "loss": null,
        "raw": {
          "seed": 4774368,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": 6291456,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 192,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {},
        "framework": null,
        "gpu_type": null,
        "gpus_per_node": null,
        "model": null,
        "network": null,
        "nic_count": null,
        "nodes": 1,
        "scale": "unknown",
        "topology": "unknown",
        "workload": "demo",
        "workload_kind": "workload"
      },
      "created_at": "2026-02-02T18:46:24.927957Z",
      "metrics": {
        "algbw_gbps": 104.0,
        "busbw_gbps": 93.60000000000001,
        "comm_time_ms": 395.2,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 988.0,
        "loss": null,
        "raw": {
          "seed": 8993604,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": 6291456,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 192,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {},
        "framework": null,
        "gpu_type": null,
        "gpus_per_node": null,
        "model": null,
        "network": null,
        "nic_count": null,
        "nodes": 1,
        "scale": "unknown",
        "topology": "unknown",
        "workload": "demo",
        "workload_kind": "workload"
      },
      "created_at": "2026-02-02T18:46:24.927968Z",
      "metrics": {
        "algbw_gbps": 104.0,
        "busbw_gbps": 93.60000000000001,
        "comm_time_ms": 391.2,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 978.0,
        "loss": null,
        "raw": {
          "seed": 8993604,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": 5242880,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 192,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {},
        "framework": null,
        "gpu_type": null,
        "gpus_per_node": null,
        "model": null,
        "network": null,
        "nic_count": null,
        "nodes": 1,
        "scale": "unknown",
        "topology": "unknown",
        "workload": "demo",
        "workload_kind": "workload"
      },
      "created_at": "2026-02-02T18:46:24.927979Z",
      "metrics": {
        "algbw_gbps": 145.0,
        "busbw_gbps": 130.5,
        "comm_time_ms": 420.00000000000006,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 1050.0,
        "loss": null,
        "raw": {
          "seed": 8654045,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": 6291456,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 192,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {},
        "framework": null,
        "gpu_type": null,
        "gpus_per_node": null,
        "model": null,
        "network": null,
        "nic_count": null,
        "nodes": 1,
        "scale": "unknown",
        "topology": "unknown",
        "workload": "demo",
        "workload_kind": "workload"
      },
      "created_at": "2026-02-02T18:46:24.927990Z",
      "metrics": {
        "algbw_gbps": 104.0,
        "busbw_gbps": 93.60000000000001,
        "comm_time_ms": 383.2,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 958.0,
        "loss": null,
        "raw": {
          "seed": 8993604,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": 6291456,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 128,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL128",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {},
        "framework": null,
        "gpu_type": null,
        "gpus_per_node": null,
        "model": null,
        "network": null,
        "nic_count": null,
        "nodes": 1,
        "scale": "unknown",
        "topology": "unknown",
        "workload": "demo",
        "workload_kind": "workload"
      },
      "created_at": "2026-02-02T18:46:24.928001Z",
      "metrics": {
        "algbw_gbps": 144.0,
        "busbw_gbps": 129.6,
        "comm_time_ms": 451.2,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 1128.0,
        "loss": null,
        "raw": {
          "seed": 14350094,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": 6291456,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 128,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL128",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {},
        "framework": null,
        "gpu_type": null,
        "gpus_per_node": null,
        "model": null,
        "network": null,
        "nic_count": null,
        "nodes": 1,
        "scale": "unknown",
        "topology": "unknown",
        "workload": "demo",
        "workload_kind": "workload"
      },
      "created_at": "2026-02-02T18:46:24.928012Z",
      "metrics": {
        "algbw_gbps": 144.0,
        "busbw_gbps": 129.6,
        "comm_time_ms": 447.2,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 1117.9999999999998,
        "loss": null,
        "raw": {
          "seed": 14350094,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": 7340032,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 128,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL128",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {},
        "framework": null,
        "gpu_type": null,
        "gpus_per_node": null,
        "model": null,
        "network": null,
        "nic_count": null,
        "nodes": 1,
        "scale": "unknown",
        "topology": "unknown",
        "workload": "demo",
        "workload_kind": "workload"
      },
      "created_at": "2026-02-02T18:46:24.928023Z",
      "metrics": {
        "algbw_gbps": 140.0,
        "busbw_gbps": 126.0,
        "comm_time_ms": 400.0,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 1000.0,
        "loss": null,
        "raw": {
          "seed": 2902740,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "RING",
        "NCCL_BUFFSIZE": 6291456,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 256,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "SIMPLE",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {},
        "framework": null,
        "gpu_type": null,
        "gpus_per_node": null,
        "model": null,
        "network": null,
        "nic_count": null,
        "nodes": 1,
        "scale": "unknown",
        "topology": "unknown",
        "workload": "demo",
        "workload_kind": "workload"
      },
      "created_at": "2026-02-02T18:46:26.355175Z",
      "metrics": {
        "algbw_gbps": 118.0,
        "busbw_gbps": 106.2,
        "comm_time_ms": 450.4000000000001,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 1126.0,
        "loss": null,
        "raw": {
          "seed": 4774368,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": 6291456,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 192,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {},
        "framework": null,
        "gpu_type": null,
        "gpus_per_node": null,
        "model": null,
        "network": null,
        "nic_count": null,
        "nodes": 1,
        "scale": "unknown",
        "topology": "unknown",
        "workload": "demo",
        "workload_kind": "workload"
      },
      "created_at": "2026-02-02T18:46:26.355187Z",
      "metrics": {
        "algbw_gbps": 104.0,
        "busbw_gbps": 93.60000000000001,
        "comm_time_ms": 395.2,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 988.0,
        "loss": null,
        "raw": {
          "seed": 8993604,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": 6291456,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 192,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {},
        "framework": null,
        "gpu_type": null,
        "gpus_per_node": null,
        "model": null,
        "network": null,
        "nic_count": null,
        "nodes": 1,
        "scale": "unknown",
        "topology": "unknown",
        "workload": "demo",
        "workload_kind": "workload"
      },
      "created_at": "2026-02-02T18:46:26.355198Z",
      "metrics": {
        "algbw_gbps": 104.0,
        "busbw_gbps": 93.60000000000001,
        "comm_time_ms": 391.2,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 978.0,
        "loss": null,
        "raw": {
          "seed": 8993604,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": 5242880,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 192,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {},
        "framework": null,
        "gpu_type": null,
        "gpus_per_node": null,
        "model": null,
        "network": null,
        "nic_count": null,
        "nodes": 1,
        "scale": "unknown",
        "topology": "unknown",
        "workload": "demo",
        "workload_kind": "workload"
      },
      "created_at": "2026-02-02T18:46:26.355209Z",
      "metrics": {
        "algbw_gbps": 145.0,
        "busbw_gbps": 130.5,
        "comm_time_ms": 420.00000000000006,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 1050.0,
        "loss": null,
        "raw": {
          "seed": 8654045,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": 6291456,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 192,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {},
        "framework": null,
        "gpu_type": null,
        "gpus_per_node": null,
        "model": null,
        "network": null,
        "nic_count": null,
        "nodes": 1,
        "scale": "unknown",
        "topology": "unknown",
        "workload": "demo",
        "workload_kind": "workload"
      },
      "created_at": "2026-02-02T18:46:26.355220Z",
      "metrics": {
        "algbw_gbps": 104.0,
        "busbw_gbps": 93.60000000000001,
        "comm_time_ms": 383.2,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 958.0,
        "loss": null,
        "raw": {
          "seed": 8993604,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": 6291456,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 128,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL128",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {},
        "framework": null,
        "gpu_type": null,
        "gpus_per_node": null,
        "model": null,
        "network": null,
        "nic_count": null,
        "nodes": 1,
        "scale": "unknown",
        "topology": "unknown",
        "workload": "demo",
        "workload_kind": "workload"
      },
      "created_at": "2026-02-02T18:46:26.355230Z",
      "metrics": {
        "algbw_gbps": 144.0,
        "busbw_gbps": 129.6,
        "comm_time_ms": 451.2,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 1128.0,
        "loss": null,
        "raw": {
          "seed": 14350094,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": 6291456,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 128,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL128",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {},
        "framework": null,
        "gpu_type": null,
        "gpus_per_node": null,
        "model": null,
        "network": null,
        "nic_count": null,
        "nodes": 1,
        "scale": "unknown",
        "topology": "unknown",
        "workload": "demo",
        "workload_kind": "workload"
      },
      "created_at": "2026-02-02T18:46:26.355241Z",
      "metrics": {
        "algbw_gbps": 144.0,
        "busbw_gbps": 129.6,
        "comm_time_ms": 447.2,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 1117.9999999999998,
        "loss": null,
        "raw": {
          "seed": 14350094,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": 7340032,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 128,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL128",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {},
        "framework": null,
        "gpu_type": null,
        "gpus_per_node": null,
        "model": null,
        "network": null,
        "nic_count": null,
        "nodes": 1,
        "scale": "unknown",
        "topology": "unknown",
        "workload": "demo",
        "workload_kind": "workload"
      },
      "created_at": "2026-02-02T18:46:26.355254Z",
      "metrics": {
        "algbw_gbps": 140.0,
        "busbw_gbps": 126.0,
        "comm_time_ms": 400.0,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 1000.0,
        "loss": null,
        "raw": {
          "seed": 2902740,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "RING",
        "NCCL_BUFFSIZE": 6291456,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 256,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "SIMPLE",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {},
        "framework": null,
        "gpu_type": null,
        "gpus_per_node": null,
        "model": null,
        "network": null,
        "nic_count": null,
        "nodes": 1,
        "scale": "unknown",
        "topology": "unknown",
        "workload": "demo",
        "workload_kind": "workload"
      },
      "created_at": "2026-02-02T18:46:28.791232Z",
      "metrics": {
        "algbw_gbps": 118.0,
        "busbw_gbps": 106.2,
        "comm_time_ms": 450.4000000000001,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 1126.0,
        "loss": null,
        "raw": {
          "seed": 4774368,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": 6291456,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 192,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {},
        "framework": null,
        "gpu_type": null,
        "gpus_per_node": null,
        "model": null,
        "network": null,
        "nic_count": null,
        "nodes": 1,
        "scale": "unknown",
        "topology": "unknown",
        "workload": "demo",
        "workload_kind": "workload"
      },
      "created_at": "2026-02-02T18:46:28.791244Z",
      "metrics": {
        "algbw_gbps": 104.0,
        "busbw_gbps": 93.60000000000001,
        "comm_time_ms": 395.2,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 988.0,
        "loss": null,
        "raw": {
          "seed": 8993604,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": 6291456,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 192,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {},
        "framework": null,
        "gpu_type": null,
        "gpus_per_node": null,
        "model": null,
        "network": null,
        "nic_count": null,
        "nodes": 1,
        "scale": "unknown",
        "topology": "unknown",
        "workload": "demo",
        "workload_kind": "workload"
      },
      "created_at": "2026-02-02T18:46:28.791256Z",
      "metrics": {
        "algbw_gbps": 104.0,
        "busbw_gbps": 93.60000000000001,
        "comm_time_ms": 391.2,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 978.0,
        "loss": null,
        "raw": {
          "seed": 8993604,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": 5242880,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 192,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {},
        "framework": null,
        "gpu_type": null,
        "gpus_per_node": null,
        "model": null,
        "network": null,
        "nic_count": null,
        "nodes": 1,
        "scale": "unknown",
        "topology": "unknown",
        "workload": "demo",
        "workload_kind": "workload"
      },
      "created_at": "2026-02-02T18:46:28.791267Z",
      "metrics": {
        "algbw_gbps": 145.0,
        "busbw_gbps": 130.5,
        "comm_time_ms": 420.00000000000006,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 1050.0,
        "loss": null,
        "raw": {
          "seed": 8654045,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": 6291456,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 192,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {},
        "framework": null,
        "gpu_type": null,
        "gpus_per_node": null,
        "model": null,
        "network": null,
        "nic_count": null,
        "nodes": 1,
        "scale": "unknown",
        "topology": "unknown",
        "workload": "demo",
        "workload_kind": "workload"
      },
      "created_at": "2026-02-02T18:46:28.791278Z",
      "metrics": {
        "algbw_gbps": 104.0,
        "busbw_gbps": 93.60000000000001,
        "comm_time_ms": 383.2,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 958.0,
        "loss": null,
        "raw": {
          "seed": 8993604,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": 6291456,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 128,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL128",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {},
        "framework": null,
        "gpu_type": null,
        "gpus_per_node": null,
        "model": null,
        "network": null,
        "nic_count": null,
        "nodes": 1,
        "scale": "unknown",
        "topology": "unknown",
        "workload": "demo",
        "workload_kind": "workload"
      },
      "created_at": "2026-02-02T18:46:28.791289Z",
      "metrics": {
        "algbw_gbps": 144.0,
        "busbw_gbps": 129.6,
        "comm_time_ms": 451.2,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 1128.0,
        "loss": null,
        "raw": {
          "seed": 14350094,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": 6291456,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 128,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL128",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {},
        "framework": null,
        "gpu_type": null,
        "gpus_per_node": null,
        "model": null,
        "network": null,
        "nic_count": null,
        "nodes": 1,
        "scale": "unknown",
        "topology": "unknown",
        "workload": "demo",
        "workload_kind": "workload"
      },
      "created_at": "2026-02-02T18:46:28.791302Z",
      "metrics": {
        "algbw_gbps": 144.0,
        "busbw_gbps": 129.6,
        "comm_time_ms": 447.2,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 1117.9999999999998,
        "loss": null,
        "raw": {
          "seed": 14350094,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": 7340032,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 128,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL128",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {},
        "framework": null,
        "gpu_type": null,
        "gpus_per_node": null,
        "model": null,
        "network": null,
        "nic_count": null,
        "nodes": 1,
        "scale": "unknown",
        "topology": "unknown",
        "workload": "demo",
        "workload_kind": "workload"
      },
      "created_at": "2026-02-02T18:46:28.791314Z",
      "metrics": {
        "algbw_gbps": 140.0,
        "busbw_gbps": 126.0,
        "comm_time_ms": 400.0,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 1000.0,
        "loss": null,
        "raw": {
          "seed": 2902740,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "RING",
        "NCCL_BUFFSIZE": 6291456,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 256,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "SIMPLE",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {},
        "framework": null,
        "gpu_type": null,
        "gpus_per_node": null,
        "model": null,
        "network": null,
        "nic_count": null,
        "nodes": 1,
        "scale": "unknown",
        "topology": "unknown",
        "workload": "demo",
        "workload_kind": "workload"
      },
      "created_at": "2026-02-02T18:46:52.630522Z",
      "metrics": {
        "algbw_gbps": 118.0,
        "busbw_gbps": 106.2,
        "comm_time_ms": 450.4000000000001,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 1126.0,
        "loss": null,
        "raw": {
          "seed": 4774368,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": 6291456,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 192,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {},
        "framework": null,
        "gpu_type": null,
        "gpus_per_node": null,
        "model": null,
        "network": null,
        "nic_count": null,
        "nodes": 1,
        "scale": "unknown",
        "topology": "unknown",
        "workload": "demo",
        "workload_kind": "workload"
      },
      "created_at": "2026-02-02T18:46:52.630534Z",
      "metrics": {
        "algbw_gbps": 104.0,
        "busbw_gbps": 93.60000000000001,
        "comm_time_ms": 395.2,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 988.0,
        "loss": null,
        "raw": {
          "seed": 8993604,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": 6291456,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 192,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {},
        "framework": null,
        "gpu_type": null,
        "gpus_per_node": null,
        "model": null,
        "network": null,
        "nic_count": null,
        "nodes": 1,
        "scale": "unknown",
        "topology": "unknown",
        "workload": "demo",
        "workload_kind": "workload"
      },
      "created_at": "2026-02-02T18:46:52.630545Z",
      "metrics": {
        "algbw_gbps": 104.0,
        "busbw_gbps": 93.60000000000001,
        "comm_time_ms": 391.2,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 978.0,
        "loss": null,
        "raw": {
          "seed": 8993604,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": 5242880,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 192,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {},
        "framework": null,
        "gpu_type": null,
        "gpus_per_node": null,
        "model": null,
        "network": null,
        "nic_count": null,
        "nodes": 1,
        "scale": "unknown",
        "topology": "unknown",
        "workload": "demo",
        "workload_kind": "workload"
      },
      "created_at": "2026-02-02T18:46:52.630556Z",
      "metrics": {
        "algbw_gbps": 145.0,
        "busbw_gbps": 130.5,
        "comm_time_ms": 420.00000000000006,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 1050.0,
        "loss": null,
        "raw": {
          "seed": 8654045,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": 6291456,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 192,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {},
        "framework": null,
        "gpu_type": null,
        "gpus_per_node": null,
        "model": null,
        "network": null,
        "nic_count": null,
        "nodes": 1,
        "scale": "unknown",
        "topology": "unknown",
        "workload": "demo",
        "workload_kind": "workload"
      },
      "created_at": "2026-02-02T18:46:52.630566Z",
      "metrics": {
        "algbw_gbps": 104.0,
        "busbw_gbps": 93.60000000000001,
        "comm_time_ms": 383.2,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 958.0,
        "loss": null,
        "raw": {
          "seed": 8993604,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": 6291456,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 128,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL128",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {},
        "framework": null,
        "gpu_type": null,
        "gpus_per_node": null,
        "model": null,
        "network": null,
        "nic_count": null,
        "nodes": 1,
        "scale": "unknown",
        "topology": "unknown",
        "workload": "demo",
        "workload_kind": "workload"
      },
      "created_at": "2026-02-02T18:46:52.630578Z",
      "metrics": {
        "algbw_gbps": 144.0,
        "busbw_gbps": 129.6,
        "comm_time_ms": 451.2,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 1128.0,
        "loss": null,
        "raw": {
          "seed": 14350094,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": 6291456,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 128,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL128",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {},
        "framework": null,
        "gpu_type": null,
        "gpus_per_node": null,
        "model": null,
        "network": null,
        "nic_count": null,
        "nodes": 1,
        "scale": "unknown",
        "topology": "unknown",
        "workload": "demo",
        "workload_kind": "workload"
      },
      "created_at": "2026-02-02T18:46:52.630590Z",
      "metrics": {
        "algbw_gbps": 144.0,
        "busbw_gbps": 129.6,
        "comm_time_ms": 447.2,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 1117.9999999999998,
        "loss": null,
        "raw": {
          "seed": 14350094,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": 7340032,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 128,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL128",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {},
        "framework": null,
        "gpu_type": null,
        "gpus_per_node": null,
        "model": null,
        "network": null,
        "nic_count": null,
        "nodes": 1,
        "scale": "unknown",
        "topology": "unknown",
        "workload": "demo",
        "workload_kind": "workload"
      },
      "created_at": "2026-02-02T18:46:52.630600Z",
      "metrics": {
        "algbw_gbps": 140.0,
        "busbw_gbps": 126.0,
        "comm_time_ms": 400.0,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 1000.0,
        "loss": null,
        "raw": {
          "seed": 2902740,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "RING",
        "NCCL_BUFFSIZE": 6291456,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 256,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "SIMPLE",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {
          "category": "llm",
          "cluster": "4-node, 32xA40, PCIe intra, 100Gbps IB",
          "collectives": [
            "AllGather",
            "ReduceScatter",
            "AllReduce"
          ],
          "framework": "PyTorch + Megatron-LM",
          "model": "Phi-2-2B",
          "parallelism": "TP(8)+DP(4)",
          "source": "AutoCCL NSDI'25 evaluation"
        },
        "framework": "PyTorch + Megatron-LM",
        "gpu_type": null,
        "gpus_per_node": null,
        "model": "Phi-2-2B",
        "network": null,
        "nic_count": null,
        "nodes": 4,
        "scale": "32-gpu",
        "topology": "a40-pcie-8gpu",
        "workload": "autoccl-phi2-2b",
        "workload_kind": "training"
      },
      "created_at": "2026-02-02T18:47:35.803600Z",
      "metrics": {
        "algbw_gbps": 138.0,
        "busbw_gbps": 121.44,
        "comm_time_ms": 609.75,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 1355.0,
        "loss": null,
        "raw": {
          "seed": 4774368,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": 6291456,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 192,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {
          "category": "llm",
          "cluster": "4-node, 32xA40, PCIe intra, 100Gbps IB",
          "collectives": [
            "AllGather",
            "ReduceScatter",
            "AllReduce"
          ],
          "framework": "PyTorch + Megatron-LM",
          "model": "Phi-2-2B",
          "parallelism": "TP(8)+DP(4)",
          "source": "AutoCCL NSDI'25 evaluation"
        },
        "framework": "PyTorch + Megatron-LM",
        "gpu_type": null,
        "gpus_per_node": null,
        "model": "Phi-2-2B",
        "network": null,
        "nic_count": null,
        "nodes": 4,
        "scale": "32-gpu",
        "topology": "a40-pcie-8gpu",
        "workload": "autoccl-phi2-2b",
        "workload_kind": "training"
      },
      "created_at": "2026-02-02T18:47:35.803623Z",
      "metrics": {
        "algbw_gbps": 114.0,
        "busbw_gbps": 100.32000000000001,
        "comm_time_ms": 531.0,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 1180.0,
        "loss": null,
        "raw": {
          "seed": 8993604,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": 6291456,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 192,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {
          "category": "llm",
          "cluster": "4-node, 32xA40, PCIe intra, 100Gbps IB",
          "collectives": [
            "AllGather",
            "ReduceScatter",
            "AllReduce"
          ],
          "framework": "PyTorch + Megatron-LM",
          "model": "Phi-2-2B",
          "parallelism": "TP(8)+DP(4)",
          "source": "AutoCCL NSDI'25 evaluation"
        },
        "framework": "PyTorch + Megatron-LM",
        "gpu_type": null,
        "gpus_per_node": null,
        "model": "Phi-2-2B",
        "network": null,
        "nic_count": null,
        "nodes": 4,
        "scale": "32-gpu",
        "topology": "a40-pcie-8gpu",
        "workload": "autoccl-phi2-2b",
        "workload_kind": "training"
      },
      "created_at": "2026-02-02T18:47:35.803645Z",
      "metrics": {
        "algbw_gbps": 114.0,
        "busbw_gbps": 100.32000000000001,
        "comm_time_ms": 524.25,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 1165.0,
        "loss": null,
        "raw": {
          "seed": 8993604,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": 7340032,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 192,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {
          "category": "llm",
          "cluster": "4-node, 32xA40, PCIe intra, 100Gbps IB",
          "collectives": [
            "AllGather",
            "ReduceScatter",
            "AllReduce"
          ],
          "framework": "PyTorch + Megatron-LM",
          "model": "Phi-2-2B",
          "parallelism": "TP(8)+DP(4)",
          "source": "AutoCCL NSDI'25 evaluation"
        },
        "framework": "PyTorch + Megatron-LM",
        "gpu_type": null,
        "gpus_per_node": null,
        "model": "Phi-2-2B",
        "network": null,
        "nic_count": null,
        "nodes": 4,
        "scale": "32-gpu",
        "topology": "a40-pcie-8gpu",
        "workload": "autoccl-phi2-2b",
        "workload_kind": "training"
      },
      "created_at": "2026-02-02T18:47:35.803667Z",
      "metrics": {
        "algbw_gbps": 110.0,
        "busbw_gbps": 96.8,
        "comm_time_ms": 513.0,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 1140.0,
        "loss": null,
        "raw": {
          "seed": 1670300,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": 6291456,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 192,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {
          "category": "llm",
          "cluster": "4-node, 32xA40, PCIe intra, 100Gbps IB",
          "collectives": [
            "AllGather",
            "ReduceScatter",
            "AllReduce"
          ],
          "framework": "PyTorch + Megatron-LM",
          "model": "Phi-2-2B",
          "parallelism": "TP(8)+DP(4)",
          "source": "AutoCCL NSDI'25 evaluation"
        },
        "framework": "PyTorch + Megatron-LM",
        "gpu_type": null,
        "gpus_per_node": null,
        "model": "Phi-2-2B",
        "network": null,
        "nic_count": null,
        "nodes": 4,
        "scale": "32-gpu",
        "topology": "a40-pcie-8gpu",
        "workload": "autoccl-phi2-2b",
        "workload_kind": "training"
      },
      "created_at": "2026-02-02T18:47:35.803720Z",
      "metrics": {
        "algbw_gbps": 114.0,
        "busbw_gbps": 100.32000000000001,
        "comm_time_ms": 510.75000000000006,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 1135.0,
        "loss": null,
        "raw": {
          "seed": 8993604,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": 6291456,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 128,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL128",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {
          "category": "llm",
          "cluster": "4-node, 32xA40, PCIe intra, 100Gbps IB",
          "collectives": [
            "AllGather",
            "ReduceScatter",
            "AllReduce"
          ],
          "framework": "PyTorch + Megatron-LM",
          "model": "Phi-2-2B",
          "parallelism": "TP(8)+DP(4)",
          "source": "AutoCCL NSDI'25 evaluation"
        },
        "framework": "PyTorch + Megatron-LM",
        "gpu_type": null,
        "gpus_per_node": null,
        "model": "Phi-2-2B",
        "network": null,
        "nic_count": null,
        "nodes": 4,
        "scale": "32-gpu",
        "topology": "a40-pcie-8gpu",
        "workload": "autoccl-phi2-2b",
        "workload_kind": "training"
      },
      "created_at": "2026-02-02T18:47:35.803750Z",
      "metrics": {
        "algbw_gbps": 104.0,
        "busbw_gbps": 91.52,
        "comm_time_ms": 605.25,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 1345.0,
        "loss": null,
        "raw": {
          "seed": 14350094,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": 6291456,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 128,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL128",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {
          "category": "llm",
          "cluster": "4-node, 32xA40, PCIe intra, 100Gbps IB",
          "collectives": [
            "AllGather",
            "ReduceScatter",
            "AllReduce"
          ],
          "framework": "PyTorch + Megatron-LM",
          "model": "Phi-2-2B",
          "parallelism": "TP(8)+DP(4)",
          "source": "AutoCCL NSDI'25 evaluation"
        },
        "framework": "PyTorch + Megatron-LM",
        "gpu_type": null,
        "gpus_per_node": null,
        "model": "Phi-2-2B",
        "network": null,
        "nic_count": null,
        "nodes": 4,
        "scale": "32-gpu",
        "topology": "a40-pcie-8gpu",
        "workload": "autoccl-phi2-2b",
        "workload_kind": "training"
      },
      "created_at": "2026-02-02T18:47:35.803777Z",
      "metrics": {
        "algbw_gbps": 104.0,
        "busbw_gbps": 91.52,
        "comm_time_ms": 598.5,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 1330.0,
        "loss": null,
        "raw": {
          "seed": 14350094,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": 4194304,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 192,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {
          "category": "llm",
          "cluster": "4-node, 32xA40, PCIe intra, 100Gbps IB",
          "collectives": [
            "AllGather",
            "ReduceScatter",
            "AllReduce"
          ],
          "framework": "PyTorch + Megatron-LM",
          "model": "Phi-2-2B",
          "parallelism": "TP(8)+DP(4)",
          "source": "AutoCCL NSDI'25 evaluation"
        },
        "framework": "PyTorch + Megatron-LM",
        "gpu_type": null,
        "gpus_per_node": null,
        "model": "Phi-2-2B",
        "network": null,
        "nic_count": null,
        "nodes": 4,
        "scale": "32-gpu",
        "topology": "a40-pcie-8gpu",
        "workload": "autoccl-phi2-2b",
        "workload_kind": "training"
      },
      "created_at": "2026-02-02T18:48:02.843156Z",
      "metrics": {
        "algbw_gbps": 117.0,
        "busbw_gbps": 102.96,
        "comm_time_ms": 586.125,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 1302.5,
        "loss": null,
        "raw": {
          "seed": 6306147,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": 4194304,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 256,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {
          "category": "llm",
          "cluster": "4-node, 32xA40, PCIe intra, 100Gbps IB",
          "collectives": [
            "AllGather",
            "ReduceScatter",
            "AllReduce"
          ],
          "framework": "PyTorch + Megatron-LM",
          "model": "Phi-2-2B",
          "parallelism": "TP(8)+DP(4)",
          "source": "AutoCCL NSDI'25 evaluation"
        },
        "framework": "PyTorch + Megatron-LM",
        "gpu_type": null,
        "gpus_per_node": null,
        "model": "Phi-2-2B",
        "network": null,
        "nic_count": null,
        "nodes": 4,
        "scale": "32-gpu",
        "topology": "a40-pcie-8gpu",
        "workload": "autoccl-phi2-2b",
        "workload_kind": "training"
      },
      "created_at": "2026-02-02T18:48:02.843175Z",
      "metrics": {
        "algbw_gbps": 100.0,
        "busbw_gbps": 88.0,
        "comm_time_ms": 627.75,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 1395.0,
        "loss": null,
        "raw": {
          "seed": 3367090,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": 4194304,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 192,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {
          "category": "llm",
          "cluster": "4-node, 32xA40, PCIe intra, 100Gbps IB",
          "collectives": [
            "AllGather",
            "ReduceScatter",
            "AllReduce"
          ],
          "framework": "PyTorch + Megatron-LM",
          "model": "Phi-2-2B",
          "parallelism": "TP(8)+DP(4)",
          "source": "AutoCCL NSDI'25 evaluation"
        },
        "framework": "PyTorch + Megatron-LM",
        "gpu_type": null,
        "gpus_per_node": null,
        "model": "Phi-2-2B",
        "network": null,
        "nic_count": null,
        "nodes": 4,
        "scale": "32-gpu",
        "topology": "a40-pcie-8gpu",
        "workload": "autoccl-phi2-2b",
        "workload_kind": "training"
      },
      "created_at": "2026-02-02T18:48:02.843194Z",
      "metrics": {
        "algbw_gbps": 117.0,
        "busbw_gbps": 102.96,
        "comm_time_ms": 572.625,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 1272.5,
        "loss": null,
        "raw": {
          "seed": 6306147,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": 3145728,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 192,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {
          "category": "llm",
          "cluster": "4-node, 32xA40, PCIe intra, 100Gbps IB",
          "collectives": [
            "AllGather",
            "ReduceScatter",
            "AllReduce"
          ],
          "framework": "PyTorch + Megatron-LM",
          "model": "Phi-2-2B",
          "parallelism": "TP(8)+DP(4)",
          "source": "AutoCCL NSDI'25 evaluation"
        },
        "framework": "PyTorch + Megatron-LM",
        "gpu_type": null,
        "gpus_per_node": null,
        "model": "Phi-2-2B",
        "network": null,
        "nic_count": null,
        "nodes": 4,
        "scale": "32-gpu",
        "topology": "a40-pcie-8gpu",
        "workload": "autoccl-phi2-2b",
        "workload_kind": "training"
      },
      "created_at": "2026-02-02T18:48:02.843212Z",
      "metrics": {
        "algbw_gbps": 145.0,
        "busbw_gbps": 127.6,
        "comm_time_ms": 574.8749999999999,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 1277.4999999999998,
        "loss": null,
        "raw": {
          "seed": 4875955,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": 3145728,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 192,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {
          "category": "llm",
          "cluster": "4-node, 32xA40, PCIe intra, 100Gbps IB",
          "collectives": [
            "AllGather",
            "ReduceScatter",
            "AllReduce"
          ],
          "framework": "PyTorch + Megatron-LM",
          "model": "Phi-2-2B",
          "parallelism": "TP(8)+DP(4)",
          "source": "AutoCCL NSDI'25 evaluation"
        },
        "framework": "PyTorch + Megatron-LM",
        "gpu_type": null,
        "gpus_per_node": null,
        "model": "Phi-2-2B",
        "network": null,
        "nic_count": null,
        "nodes": 4,
        "scale": "32-gpu",
        "topology": "a40-pcie-8gpu",
        "workload": "autoccl-phi2-2b",
        "workload_kind": "training"
      },
      "created_at": "2026-02-02T18:48:02.843229Z",
      "metrics": {
        "algbw_gbps": 145.0,
        "busbw_gbps": 127.6,
        "comm_time_ms": 568.125,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 1262.5,
        "loss": null,
        "raw": {
          "seed": 4875955,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": 3145728,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 256,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL128",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {
          "category": "llm",
          "cluster": "4-node, 32xA40, PCIe intra, 100Gbps IB",
          "collectives": [
            "AllGather",
            "ReduceScatter",
            "AllReduce"
          ],
          "framework": "PyTorch + Megatron-LM",
          "model": "Phi-2-2B",
          "parallelism": "TP(8)+DP(4)",
          "source": "AutoCCL NSDI'25 evaluation"
        },
        "framework": "PyTorch + Megatron-LM",
        "gpu_type": null,
        "gpus_per_node": null,
        "model": "Phi-2-2B",
        "network": null,
        "nic_count": null,
        "nodes": 4,
        "scale": "32-gpu",
        "topology": "a40-pcie-8gpu",
        "workload": "autoccl-phi2-2b",
        "workload_kind": "training"
      },
      "created_at": "2026-02-02T18:48:02.843246Z",
      "metrics": {
        "algbw_gbps": 124.0,
        "busbw_gbps": 109.12,
        "comm_time_ms": 560.2499999999999,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 1244.9999999999998,
        "loss": null,
        "raw": {
          "seed": 15878554,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": 3145728,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 192,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {
          "category": "llm",
          "cluster": "4-node, 32xA40, PCIe intra, 100Gbps IB",
          "collectives": [
            "AllGather",
            "ReduceScatter",
            "AllReduce"
          ],
          "framework": "PyTorch + Megatron-LM",
          "model": "Phi-2-2B",
          "parallelism": "TP(8)+DP(4)",
          "source": "AutoCCL NSDI'25 evaluation"
        },
        "framework": "PyTorch + Megatron-LM",
        "gpu_type": null,
        "gpus_per_node": null,
        "model": "Phi-2-2B",
        "network": null,
        "nic_count": null,
        "nodes": 4,
        "scale": "32-gpu",
        "topology": "a40-pcie-8gpu",
        "workload": "autoccl-phi2-2b",
        "workload_kind": "training"
      },
      "created_at": "2026-02-02T18:48:02.843266Z",
      "metrics": {
        "algbw_gbps": 145.0,
        "busbw_gbps": 127.6,
        "comm_time_ms": 554.625,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 1232.5,
        "loss": null,
        "raw": {
          "seed": 4875955,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": 2097152,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 192,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL128",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {
          "category": "llm",
          "cluster": "4-node, 32xA40, PCIe intra, 100Gbps IB",
          "collectives": [
            "AllGather",
            "ReduceScatter",
            "AllReduce"
          ],
          "framework": "PyTorch + Megatron-LM",
          "model": "Phi-2-2B",
          "parallelism": "TP(8)+DP(4)",
          "source": "AutoCCL NSDI'25 evaluation"
        },
        "framework": "PyTorch + Megatron-LM",
        "gpu_type": null,
        "gpus_per_node": null,
        "model": "Phi-2-2B",
        "network": null,
        "nic_count": null,
        "nodes": 4,
        "scale": "32-gpu",
        "topology": "a40-pcie-8gpu",
        "workload": "autoccl-phi2-2b",
        "workload_kind": "training"
      },
      "created_at": "2026-02-02T18:48:02.843283Z",
      "metrics": {
        "algbw_gbps": 99.0,
        "busbw_gbps": 87.12,
        "comm_time_ms": 518.625,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 1152.4999999999998,
        "loss": null,
        "raw": {
          "seed": 5606229,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": 2097152,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 192,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {
          "category": "llm",
          "cluster": "4-node, 32xA40, PCIe intra, 100Gbps IB",
          "collectives": [
            "AllGather",
            "ReduceScatter",
            "AllReduce"
          ],
          "framework": "PyTorch + Megatron-LM",
          "model": "Phi-2-2B",
          "parallelism": "TP(8)+DP(4)",
          "source": "AutoCCL NSDI'25 evaluation"
        },
        "framework": "PyTorch + Megatron-LM",
        "gpu_type": null,
        "gpus_per_node": null,
        "model": "Phi-2-2B",
        "network": null,
        "nic_count": null,
        "nodes": 4,
        "scale": "32-gpu",
        "topology": "a40-pcie-8gpu",
        "workload": "autoccl-phi2-2b",
        "workload_kind": "training"
      },
      "created_at": "2026-02-02T18:48:02.843299Z",
      "metrics": {
        "algbw_gbps": 131.0,
        "busbw_gbps": 115.28,
        "comm_time_ms": 480.37499999999994,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 1067.5,
        "loss": null,
        "raw": {
          "seed": 4100501,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "RING",
        "NCCL_BUFFSIZE": 2097152,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 256,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "SIMPLE",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {
          "category": "llm",
          "cluster": "4-node, 32xA40, PCIe intra, 100Gbps IB",
          "collectives": [
            "AllGather",
            "ReduceScatter",
            "AllReduce"
          ],
          "framework": "PyTorch + Megatron-LM",
          "model": "Phi-2-2B",
          "parallelism": "TP(8)+DP(4)",
          "source": "AutoCCL NSDI'25 evaluation"
        },
        "framework": "PyTorch + Megatron-LM",
        "gpu_type": null,
        "gpus_per_node": null,
        "model": "Phi-2-2B",
        "network": null,
        "nic_count": null,
        "nodes": 4,
        "scale": "32-gpu",
        "topology": "a40-pcie-8gpu",
        "workload": "autoccl-phi2-2b",
        "workload_kind": "training"
      },
      "created_at": "2026-02-02T18:48:04.542907Z",
      "metrics": {
        "algbw_gbps": 125.0,
        "busbw_gbps": 110.0,
        "comm_time_ms": 640.125,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 1422.5,
        "loss": null,
        "raw": {
          "seed": 16460795,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": 2097152,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 192,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {
          "category": "llm",
          "cluster": "4-node, 32xA40, PCIe intra, 100Gbps IB",
          "collectives": [
            "AllGather",
            "ReduceScatter",
            "AllReduce"
          ],
          "framework": "PyTorch + Megatron-LM",
          "model": "Phi-2-2B",
          "parallelism": "TP(8)+DP(4)",
          "source": "AutoCCL NSDI'25 evaluation"
        },
        "framework": "PyTorch + Megatron-LM",
        "gpu_type": null,
        "gpus_per_node": null,
        "model": "Phi-2-2B",
        "network": null,
        "nic_count": null,
        "nodes": 4,
        "scale": "32-gpu",
        "topology": "a40-pcie-8gpu",
        "workload": "autoccl-phi2-2b",
        "workload_kind": "training"
      },
      "created_at": "2026-02-02T18:48:04.542931Z",
      "metrics": {
        "algbw_gbps": 131.0,
        "busbw_gbps": 115.28,
        "comm_time_ms": 527.625,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 1172.4999999999998,
        "loss": null,
        "raw": {
          "seed": 4100501,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": 2097152,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 192,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {
          "category": "llm",
          "cluster": "4-node, 32xA40, PCIe intra, 100Gbps IB",
          "collectives": [
            "AllGather",
            "ReduceScatter",
            "AllReduce"
          ],
          "framework": "PyTorch + Megatron-LM",
          "model": "Phi-2-2B",
          "parallelism": "TP(8)+DP(4)",
          "source": "AutoCCL NSDI'25 evaluation"
        },
        "framework": "PyTorch + Megatron-LM",
        "gpu_type": null,
        "gpus_per_node": null,
        "model": "Phi-2-2B",
        "network": null,
        "nic_count": null,
        "nodes": 4,
        "scale": "32-gpu",
        "topology": "a40-pcie-8gpu",
        "workload": "autoccl-phi2-2b",
        "workload_kind": "training"
      },
      "created_at": "2026-02-02T18:48:04.542957Z",
      "metrics": {
        "algbw_gbps": 131.0,
        "busbw_gbps": 115.28,
        "comm_time_ms": 520.875,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 1157.5,
        "loss": null,
        "raw": {
          "seed": 4100501,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": 1048576,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 192,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {
          "category": "llm",
          "cluster": "4-node, 32xA40, PCIe intra, 100Gbps IB",
          "collectives": [
            "AllGather",
            "ReduceScatter",
            "AllReduce"
          ],
          "framework": "PyTorch + Megatron-LM",
          "model": "Phi-2-2B",
          "parallelism": "TP(8)+DP(4)",
          "source": "AutoCCL NSDI'25 evaluation"
        },
        "framework": "PyTorch + Megatron-LM",
        "gpu_type": null,
        "gpus_per_node": null,
        "model": "Phi-2-2B",
        "network": null,
        "nic_count": null,
        "nodes": 4,
        "scale": "32-gpu",
        "topology": "a40-pcie-8gpu",
        "workload": "autoccl-phi2-2b",
        "workload_kind": "training"
      },
      "created_at": "2026-02-02T18:48:04.542980Z",
      "metrics": {
        "algbw_gbps": 121.0,
        "busbw_gbps": 106.48,
        "comm_time_ms": 525.375,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 1167.5,
        "loss": null,
        "raw": {
          "seed": 11533411,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": 2097152,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 192,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {
          "category": "llm",
          "cluster": "4-node, 32xA40, PCIe intra, 100Gbps IB",
          "collectives": [
            "AllGather",
            "ReduceScatter",
            "AllReduce"
          ],
          "framework": "PyTorch + Megatron-LM",
          "model": "Phi-2-2B",
          "parallelism": "TP(8)+DP(4)",
          "source": "AutoCCL NSDI'25 evaluation"
        },
        "framework": "PyTorch + Megatron-LM",
        "gpu_type": null,
        "gpus_per_node": null,
        "model": "Phi-2-2B",
        "network": null,
        "nic_count": null,
        "nodes": 4,
        "scale": "32-gpu",
        "topology": "a40-pcie-8gpu",
        "workload": "autoccl-phi2-2b",
        "workload_kind": "training"
      },
      "created_at": "2026-02-02T18:48:04.543003Z",
      "metrics": {
        "algbw_gbps": 131.0,
        "busbw_gbps": 115.28,
        "comm_time_ms": 507.375,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 1127.5,
        "loss": null,
        "raw": {
          "seed": 4100501,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": 2097152,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 256,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL128",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {
          "category": "llm",
          "cluster": "4-node, 32xA40, PCIe intra, 100Gbps IB",
          "collectives": [
            "AllGather",
            "ReduceScatter",
            "AllReduce"
          ],
          "framework": "PyTorch + Megatron-LM",
          "model": "Phi-2-2B",
          "parallelism": "TP(8)+DP(4)",
          "source": "AutoCCL NSDI'25 evaluation"
        },
        "framework": "PyTorch + Megatron-LM",
        "gpu_type": null,
        "gpus_per_node": null,
        "model": "Phi-2-2B",
        "network": null,
        "nic_count": null,
        "nodes": 4,
        "scale": "32-gpu",
        "topology": "a40-pcie-8gpu",
        "workload": "autoccl-phi2-2b",
        "workload_kind": "training"
      },
      "created_at": "2026-02-02T18:48:04.543026Z",
      "metrics": {
        "algbw_gbps": 110.0,
        "busbw_gbps": 96.8,
        "comm_time_ms": 522.0,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 1160.0,
        "loss": null,
        "raw": {
          "seed": 7492220,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": 2097152,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 256,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL128",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {
          "category": "llm",
          "cluster": "4-node, 32xA40, PCIe intra, 100Gbps IB",
          "collectives": [
            "AllGather",
            "ReduceScatter",
            "AllReduce"
          ],
          "framework": "PyTorch + Megatron-LM",
          "model": "Phi-2-2B",
          "parallelism": "TP(8)+DP(4)",
          "source": "AutoCCL NSDI'25 evaluation"
        },
        "framework": "PyTorch + Megatron-LM",
        "gpu_type": null,
        "gpus_per_node": null,
        "model": "Phi-2-2B",
        "network": null,
        "nic_count": null,
        "nodes": 4,
        "scale": "32-gpu",
        "topology": "a40-pcie-8gpu",
        "workload": "autoccl-phi2-2b",
        "workload_kind": "training"
      },
      "created_at": "2026-02-02T18:48:04.543049Z",
      "metrics": {
        "algbw_gbps": 110.0,
        "busbw_gbps": 96.8,
        "comm_time_ms": 515.25,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 1145.0,
        "loss": null,
        "raw": {
          "seed": 7492220,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": 3145728,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 256,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL128",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {
          "category": "llm",
          "cluster": "4-node, 32xA40, PCIe intra, 100Gbps IB",
          "collectives": [
            "AllGather",
            "ReduceScatter",
            "AllReduce"
          ],
          "framework": "PyTorch + Megatron-LM",
          "model": "Phi-2-2B",
          "parallelism": "TP(8)+DP(4)",
          "source": "AutoCCL NSDI'25 evaluation"
        },
        "framework": "PyTorch + Megatron-LM",
        "gpu_type": null,
        "gpus_per_node": null,
        "model": "Phi-2-2B",
        "network": null,
        "nic_count": null,
        "nodes": 4,
        "scale": "32-gpu",
        "topology": "a40-pcie-8gpu",
        "workload": "autoccl-phi2-2b",
        "workload_kind": "training"
      },
      "created_at": "2026-02-02T18:48:04.543069Z",
      "metrics": {
        "algbw_gbps": 124.0,
        "busbw_gbps": 109.12,
        "comm_time_ms": 546.75,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 1214.9999999999998,
        "loss": null,
        "raw": {
          "seed": 15878554,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": 4194304,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 192,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {
          "category": "llm",
          "cluster": "4-node, 32xA40, PCIe intra, 100Gbps IB",
          "collectives": [
            "AllGather",
            "ReduceScatter",
            "AllReduce"
          ],
          "framework": "PyTorch + Megatron-LM",
          "model": "Phi-2-2B",
          "parallelism": "TP(8)+DP(4)",
          "source": "AutoCCL NSDI'25 evaluation"
        },
        "framework": "PyTorch + Megatron-LM",
        "gpu_type": null,
        "gpus_per_node": null,
        "model": "Phi-2-2B",
        "network": null,
        "nic_count": null,
        "nodes": 4,
        "scale": "32-gpu",
        "topology": "a40-pcie-8gpu",
        "workload": "autoccl-phi2-2b",
        "workload_kind": "training"
      },
      "created_at": "2026-02-02T18:48:05.711831Z",
      "metrics": {
        "algbw_gbps": 117.0,
        "busbw_gbps": 102.96,
        "comm_time_ms": 586.125,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 1302.5,
        "loss": null,
        "raw": {
          "seed": 6306147,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": 4194304,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 256,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {
          "category": "llm",
          "cluster": "4-node, 32xA40, PCIe intra, 100Gbps IB",
          "collectives": [
            "AllGather",
            "ReduceScatter",
            "AllReduce"
          ],
          "framework": "PyTorch + Megatron-LM",
          "model": "Phi-2-2B",
          "parallelism": "TP(8)+DP(4)",
          "source": "AutoCCL NSDI'25 evaluation"
        },
        "framework": "PyTorch + Megatron-LM",
        "gpu_type": null,
        "gpus_per_node": null,
        "model": "Phi-2-2B",
        "network": null,
        "nic_count": null,
        "nodes": 4,
        "scale": "32-gpu",
        "topology": "a40-pcie-8gpu",
        "workload": "autoccl-phi2-2b",
        "workload_kind": "training"
      },
      "created_at": "2026-02-02T18:48:05.711855Z",
      "metrics": {
        "algbw_gbps": 100.0,
        "busbw_gbps": 88.0,
        "comm_time_ms": 627.75,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 1395.0,
        "loss": null,
        "raw": {
          "seed": 3367090,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": 4194304,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 192,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {
          "category": "llm",
          "cluster": "4-node, 32xA40, PCIe intra, 100Gbps IB",
          "collectives": [
            "AllGather",
            "ReduceScatter",
            "AllReduce"
          ],
          "framework": "PyTorch + Megatron-LM",
          "model": "Phi-2-2B",
          "parallelism": "TP(8)+DP(4)",
          "source": "AutoCCL NSDI'25 evaluation"
        },
        "framework": "PyTorch + Megatron-LM",
        "gpu_type": null,
        "gpus_per_node": null,
        "model": "Phi-2-2B",
        "network": null,
        "nic_count": null,
        "nodes": 4,
        "scale": "32-gpu",
        "topology": "a40-pcie-8gpu",
        "workload": "autoccl-phi2-2b",
        "workload_kind": "training"
      },
      "created_at": "2026-02-02T18:48:05.711877Z",
      "metrics": {
        "algbw_gbps": 117.0,
        "busbw_gbps": 102.96,
        "comm_time_ms": 572.625,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 1272.5,
        "loss": null,
        "raw": {
          "seed": 6306147,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": 5242880,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 192,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {
          "category": "llm",
          "cluster": "4-node, 32xA40, PCIe intra, 100Gbps IB",
          "collectives": [
            "AllGather",
            "ReduceScatter",
            "AllReduce"
          ],
          "framework": "PyTorch + Megatron-LM",
          "model": "Phi-2-2B",
          "parallelism": "TP(8)+DP(4)",
          "source": "AutoCCL NSDI'25 evaluation"
        },
        "framework": "PyTorch + Megatron-LM",
        "gpu_type": null,
        "gpus_per_node": null,
        "model": "Phi-2-2B",
        "network": null,
        "nic_count": null,
        "nodes": 4,
        "scale": "32-gpu",
        "topology": "a40-pcie-8gpu",
        "workload": "autoccl-phi2-2b",
        "workload_kind": "training"
      },
      "created_at": "2026-02-02T18:48:05.711899Z",
      "metrics": {
        "algbw_gbps": 95.0,
        "busbw_gbps": 83.6,
        "comm_time_ms": 563.625,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 1252.5,
        "loss": null,
        "raw": {
          "seed": 8654045,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": 5242880,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 192,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {
          "category": "llm",
          "cluster": "4-node, 32xA40, PCIe intra, 100Gbps IB",
          "collectives": [
            "AllGather",
            "ReduceScatter",
            "AllReduce"
          ],
          "framework": "PyTorch + Megatron-LM",
          "model": "Phi-2-2B",
          "parallelism": "TP(8)+DP(4)",
          "source": "AutoCCL NSDI'25 evaluation"
        },
        "framework": "PyTorch + Megatron-LM",
        "gpu_type": null,
        "gpus_per_node": null,
        "model": "Phi-2-2B",
        "network": null,
        "nic_count": null,
        "nodes": 4,
        "scale": "32-gpu",
        "topology": "a40-pcie-8gpu",
        "workload": "autoccl-phi2-2b",
        "workload_kind": "training"
      },
      "created_at": "2026-02-02T18:48:05.711920Z",
      "metrics": {
        "algbw_gbps": 95.0,
        "busbw_gbps": 83.6,
        "comm_time_ms": 556.875,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 1237.5,
        "loss": null,
        "raw": {
          "seed": 8654045,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": 5242880,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 256,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL128",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {
          "category": "llm",
          "cluster": "4-node, 32xA40, PCIe intra, 100Gbps IB",
          "collectives": [
            "AllGather",
            "ReduceScatter",
            "AllReduce"
          ],
          "framework": "PyTorch + Megatron-LM",
          "model": "Phi-2-2B",
          "parallelism": "TP(8)+DP(4)",
          "source": "AutoCCL NSDI'25 evaluation"
        },
        "framework": "PyTorch + Megatron-LM",
        "gpu_type": null,
        "gpus_per_node": null,
        "model": "Phi-2-2B",
        "network": null,
        "nic_count": null,
        "nodes": 4,
        "scale": "32-gpu",
        "topology": "a40-pcie-8gpu",
        "workload": "autoccl-phi2-2b",
        "workload_kind": "training"
      },
      "created_at": "2026-02-02T18:48:05.711939Z",
      "metrics": {
        "algbw_gbps": 144.0,
        "busbw_gbps": 126.72,
        "comm_time_ms": 515.2499999999999,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 1144.9999999999998,
        "loss": null,
        "raw": {
          "seed": 15787014,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": 5242880,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 192,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {
          "category": "llm",
          "cluster": "4-node, 32xA40, PCIe intra, 100Gbps IB",
          "collectives": [
            "AllGather",
            "ReduceScatter",
            "AllReduce"
          ],
          "framework": "PyTorch + Megatron-LM",
          "model": "Phi-2-2B",
          "parallelism": "TP(8)+DP(4)",
          "source": "AutoCCL NSDI'25 evaluation"
        },
        "framework": "PyTorch + Megatron-LM",
        "gpu_type": null,
        "gpus_per_node": null,
        "model": "Phi-2-2B",
        "network": null,
        "nic_count": null,
        "nodes": 4,
        "scale": "32-gpu",
        "topology": "a40-pcie-8gpu",
        "workload": "autoccl-phi2-2b",
        "workload_kind": "training"
      },
      "created_at": "2026-02-02T18:48:05.711959Z",
      "metrics": {
        "algbw_gbps": 95.0,
        "busbw_gbps": 83.6,
        "comm_time_ms": 543.375,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 1207.5,
        "loss": null,
        "raw": {
          "seed": 8654045,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": 4194304,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 192,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL128",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {
          "category": "llm",
          "cluster": "4-node, 32xA40, PCIe intra, 100Gbps IB",
          "collectives": [
            "AllGather",
            "ReduceScatter",
            "AllReduce"
          ],
          "framework": "PyTorch + Megatron-LM",
          "model": "Phi-2-2B",
          "parallelism": "TP(8)+DP(4)",
          "source": "AutoCCL NSDI'25 evaluation"
        },
        "framework": "PyTorch + Megatron-LM",
        "gpu_type": null,
        "gpus_per_node": null,
        "model": "Phi-2-2B",
        "network": null,
        "nic_count": null,
        "nodes": 4,
        "scale": "32-gpu",
        "topology": "a40-pcie-8gpu",
        "workload": "autoccl-phi2-2b",
        "workload_kind": "training"
      },
      "created_at": "2026-02-02T18:48:05.711978Z",
      "metrics": {
        "algbw_gbps": 95.0,
        "busbw_gbps": 83.6,
        "comm_time_ms": 559.1250000000001,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 1242.5000000000002,
        "loss": null,
        "raw": {
          "seed": 3620465,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": 4194304,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 192,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {
          "category": "llm",
          "cluster": "4-node, 32xA40, PCIe intra, 100Gbps IB",
          "collectives": [
            "AllGather",
            "ReduceScatter",
            "AllReduce"
          ],
          "framework": "PyTorch + Megatron-LM",
          "model": "Phi-2-2B",
          "parallelism": "TP(8)+DP(4)",
          "source": "AutoCCL NSDI'25 evaluation"
        },
        "framework": "PyTorch + Megatron-LM",
        "gpu_type": null,
        "gpus_per_node": null,
        "model": "Phi-2-2B",
        "network": null,
        "nic_count": null,
        "nodes": 4,
        "scale": "32-gpu",
        "topology": "a40-pcie-8gpu",
        "workload": "autoccl-phi2-2b",
        "workload_kind": "training"
      },
      "created_at": "2026-02-02T18:48:05.711997Z",
      "metrics": {
        "algbw_gbps": 117.0,
        "busbw_gbps": 102.96,
        "comm_time_ms": 532.125,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 1182.4999999999998,
        "loss": null,
        "raw": {
          "seed": 6306147,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": 2097152,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 192,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {
          "category": "llm",
          "cluster": "4-node, 32xA40, PCIe intra, 100Gbps IB",
          "collectives": [
            "AllGather",
            "ReduceScatter",
            "AllReduce"
          ],
          "framework": "PyTorch + Megatron-LM",
          "model": "Phi-2-2B",
          "parallelism": "TP(8)+DP(4)",
          "source": "AutoCCL NSDI'25 evaluation"
        },
        "framework": "PyTorch + Megatron-LM",
        "gpu_type": null,
        "gpus_per_node": null,
        "model": "Phi-2-2B",
        "network": null,
        "nic_count": null,
        "nodes": 4,
        "scale": "32-gpu",
        "topology": "a40-pcie-8gpu",
        "workload": "autoccl-phi2-2b",
        "workload_kind": "training"
      },
      "created_at": "2026-02-02T18:56:14.188792Z",
      "metrics": {
        "algbw_gbps": 131.0,
        "busbw_gbps": 115.28,
        "comm_time_ms": 534.375,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 1187.5,
        "loss": null,
        "raw": {
          "seed": 4100501,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": 2097152,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 256,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {
          "category": "llm",
          "cluster": "4-node, 32xA40, PCIe intra, 100Gbps IB",
          "collectives": [
            "AllGather",
            "ReduceScatter",
            "AllReduce"
          ],
          "framework": "PyTorch + Megatron-LM",
          "model": "Phi-2-2B",
          "parallelism": "TP(8)+DP(4)",
          "source": "AutoCCL NSDI'25 evaluation"
        },
        "framework": "PyTorch + Megatron-LM",
        "gpu_type": null,
        "gpus_per_node": null,
        "model": "Phi-2-2B",
        "network": null,
        "nic_count": null,
        "nodes": 4,
        "scale": "32-gpu",
        "topology": "a40-pcie-8gpu",
        "workload": "autoccl-phi2-2b",
        "workload_kind": "training"
      },
      "created_at": "2026-02-02T18:56:14.188890Z",
      "metrics": {
        "algbw_gbps": 115.0,
        "busbw_gbps": 101.2,
        "comm_time_ms": 532.125,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 1182.4999999999998,
        "loss": null,
        "raw": {
          "seed": 11532805,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": 2097152,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 192,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {
          "category": "llm",
          "cluster": "4-node, 32xA40, PCIe intra, 100Gbps IB",
          "collectives": [
            "AllGather",
            "ReduceScatter",
            "AllReduce"
          ],
          "framework": "PyTorch + Megatron-LM",
          "model": "Phi-2-2B",
          "parallelism": "TP(8)+DP(4)",
          "source": "AutoCCL NSDI'25 evaluation"
        },
        "framework": "PyTorch + Megatron-LM",
        "gpu_type": null,
        "gpus_per_node": null,
        "model": "Phi-2-2B",
        "network": null,
        "nic_count": null,
        "nodes": 4,
        "scale": "32-gpu",
        "topology": "a40-pcie-8gpu",
        "workload": "autoccl-phi2-2b",
        "workload_kind": "training"
      },
      "created_at": "2026-02-02T18:56:14.189011Z",
      "metrics": {
        "algbw_gbps": 131.0,
        "busbw_gbps": 115.28,
        "comm_time_ms": 520.875,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 1157.5,
        "loss": null,
        "raw": {
          "seed": 4100501,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": 1048576,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 192,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {
          "category": "llm",
          "cluster": "4-node, 32xA40, PCIe intra, 100Gbps IB",
          "collectives": [
            "AllGather",
            "ReduceScatter",
            "AllReduce"
          ],
          "framework": "PyTorch + Megatron-LM",
          "model": "Phi-2-2B",
          "parallelism": "TP(8)+DP(4)",
          "source": "AutoCCL NSDI'25 evaluation"
        },
        "framework": "PyTorch + Megatron-LM",
        "gpu_type": null,
        "gpus_per_node": null,
        "model": "Phi-2-2B",
        "network": null,
        "nic_count": null,
        "nodes": 4,
        "scale": "32-gpu",
        "topology": "a40-pcie-8gpu",
        "workload": "autoccl-phi2-2b",
        "workload_kind": "training"
      },
      "created_at": "2026-02-02T18:56:14.189056Z",
      "metrics": {
        "algbw_gbps": 121.0,
        "busbw_gbps": 106.48,
        "comm_time_ms": 525.375,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 1167.5,
        "loss": null,
        "raw": {
          "seed": 11533411,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": 1048576,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 192,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {
          "category": "llm",
          "cluster": "4-node, 32xA40, PCIe intra, 100Gbps IB",
          "collectives": [
            "AllGather",
            "ReduceScatter",
            "AllReduce"
          ],
          "framework": "PyTorch + Megatron-LM",
          "model": "Phi-2-2B",
          "parallelism": "TP(8)+DP(4)",
          "source": "AutoCCL NSDI'25 evaluation"
        },
        "framework": "PyTorch + Megatron-LM",
        "gpu_type": null,
        "gpus_per_node": null,
        "model": "Phi-2-2B",
        "network": null,
        "nic_count": null,
        "nodes": 4,
        "scale": "32-gpu",
        "topology": "a40-pcie-8gpu",
        "workload": "autoccl-phi2-2b",
        "workload_kind": "training"
      },
      "created_at": "2026-02-02T18:56:14.189097Z",
      "metrics": {
        "algbw_gbps": 121.0,
        "busbw_gbps": 106.48,
        "comm_time_ms": 518.625,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 1152.5,
        "loss": null,
        "raw": {
          "seed": 11533411,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": 1048576,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 128,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL128",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {
          "category": "llm",
          "cluster": "4-node, 32xA40, PCIe intra, 100Gbps IB",
          "collectives": [
            "AllGather",
            "ReduceScatter",
            "AllReduce"
          ],
          "framework": "PyTorch + Megatron-LM",
          "model": "Phi-2-2B",
          "parallelism": "TP(8)+DP(4)",
          "source": "AutoCCL NSDI'25 evaluation"
        },
        "framework": "PyTorch + Megatron-LM",
        "gpu_type": null,
        "gpus_per_node": null,
        "model": "Phi-2-2B",
        "network": null,
        "nic_count": null,
        "nodes": 4,
        "scale": "32-gpu",
        "topology": "a40-pcie-8gpu",
        "workload": "autoccl-phi2-2b",
        "workload_kind": "training"
      },
      "created_at": "2026-02-02T18:56:14.189142Z",
      "metrics": {
        "algbw_gbps": 97.0,
        "busbw_gbps": 85.36,
        "comm_time_ms": 574.8749999999999,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 1277.4999999999998,
        "loss": null,
        "raw": {
          "seed": 4898467,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": 4194304,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 192,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {
          "category": "llm",
          "cluster": "4-node, 32xA40, PCIe intra, 100Gbps IB",
          "collectives": [
            "AllGather",
            "ReduceScatter",
            "AllReduce"
          ],
          "framework": "PyTorch + Megatron-LM",
          "model": "Phi-2-2B",
          "parallelism": "TP(8)+DP(4)",
          "source": "AutoCCL NSDI'25 evaluation"
        },
        "framework": "PyTorch + Megatron-LM",
        "gpu_type": null,
        "gpus_per_node": null,
        "model": "Phi-2-2B",
        "network": null,
        "nic_count": null,
        "nodes": 4,
        "scale": "32-gpu",
        "topology": "a40-pcie-8gpu",
        "workload": "autoccl-phi2-2b",
        "workload_kind": "training"
      },
      "created_at": "2026-02-02T18:56:35.621108Z",
      "metrics": {
        "algbw_gbps": 117.0,
        "busbw_gbps": 102.96,
        "comm_time_ms": 586.125,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 1302.5,
        "loss": null,
        "raw": {
          "seed": 6306147,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": 4194304,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 256,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {
          "category": "llm",
          "cluster": "4-node, 32xA40, PCIe intra, 100Gbps IB",
          "collectives": [
            "AllGather",
            "ReduceScatter",
            "AllReduce"
          ],
          "framework": "PyTorch + Megatron-LM",
          "model": "Phi-2-2B",
          "parallelism": "TP(8)+DP(4)",
          "source": "AutoCCL NSDI'25 evaluation"
        },
        "framework": "PyTorch + Megatron-LM",
        "gpu_type": null,
        "gpus_per_node": null,
        "model": "Phi-2-2B",
        "network": null,
        "nic_count": null,
        "nodes": 4,
        "scale": "32-gpu",
        "topology": "a40-pcie-8gpu",
        "workload": "autoccl-phi2-2b",
        "workload_kind": "training"
      },
      "created_at": "2026-02-02T18:56:35.621155Z",
      "metrics": {
        "algbw_gbps": 100.0,
        "busbw_gbps": 88.0,
        "comm_time_ms": 627.75,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 1395.0,
        "loss": null,
        "raw": {
          "seed": 3367090,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": 4194304,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 192,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {
          "category": "llm",
          "cluster": "4-node, 32xA40, PCIe intra, 100Gbps IB",
          "collectives": [
            "AllGather",
            "ReduceScatter",
            "AllReduce"
          ],
          "framework": "PyTorch + Megatron-LM",
          "model": "Phi-2-2B",
          "parallelism": "TP(8)+DP(4)",
          "source": "AutoCCL NSDI'25 evaluation"
        },
        "framework": "PyTorch + Megatron-LM",
        "gpu_type": null,
        "gpus_per_node": null,
        "model": "Phi-2-2B",
        "network": null,
        "nic_count": null,
        "nodes": 4,
        "scale": "32-gpu",
        "topology": "a40-pcie-8gpu",
        "workload": "autoccl-phi2-2b",
        "workload_kind": "training"
      },
      "created_at": "2026-02-02T18:56:35.621196Z",
      "metrics": {
        "algbw_gbps": 117.0,
        "busbw_gbps": 102.96,
        "comm_time_ms": 572.625,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 1272.5,
        "loss": null,
        "raw": {
          "seed": 6306147,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": 5242880,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 192,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {
          "category": "llm",
          "cluster": "4-node, 32xA40, PCIe intra, 100Gbps IB",
          "collectives": [
            "AllGather",
            "ReduceScatter",
            "AllReduce"
          ],
          "framework": "PyTorch + Megatron-LM",
          "model": "Phi-2-2B",
          "parallelism": "TP(8)+DP(4)",
          "source": "AutoCCL NSDI'25 evaluation"
        },
        "framework": "PyTorch + Megatron-LM",
        "gpu_type": null,
        "gpus_per_node": null,
        "model": "Phi-2-2B",
        "network": null,
        "nic_count": null,
        "nodes": 4,
        "scale": "32-gpu",
        "topology": "a40-pcie-8gpu",
        "workload": "autoccl-phi2-2b",
        "workload_kind": "training"
      },
      "created_at": "2026-02-02T18:56:35.621236Z",
      "metrics": {
        "algbw_gbps": 95.0,
        "busbw_gbps": 83.6,
        "comm_time_ms": 563.625,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 1252.5,
        "loss": null,
        "raw": {
          "seed": 8654045,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": 5242880,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 192,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {
          "category": "llm",
          "cluster": "4-node, 32xA40, PCIe intra, 100Gbps IB",
          "collectives": [
            "AllGather",
            "ReduceScatter",
            "AllReduce"
          ],
          "framework": "PyTorch + Megatron-LM",
          "model": "Phi-2-2B",
          "parallelism": "TP(8)+DP(4)",
          "source": "AutoCCL NSDI'25 evaluation"
        },
        "framework": "PyTorch + Megatron-LM",
        "gpu_type": null,
        "gpus_per_node": null,
        "model": "Phi-2-2B",
        "network": null,
        "nic_count": null,
        "nodes": 4,
        "scale": "32-gpu",
        "topology": "a40-pcie-8gpu",
        "workload": "autoccl-phi2-2b",
        "workload_kind": "training"
      },
      "created_at": "2026-02-02T18:56:35.621274Z",
      "metrics": {
        "algbw_gbps": 95.0,
        "busbw_gbps": 83.6,
        "comm_time_ms": 556.875,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 1237.5,
        "loss": null,
        "raw": {
          "seed": 8654045,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": 5242880,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 128,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL128",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {
          "category": "llm",
          "cluster": "4-node, 32xA40, PCIe intra, 100Gbps IB",
          "collectives": [
            "AllGather",
            "ReduceScatter",
            "AllReduce"
          ],
          "framework": "PyTorch + Megatron-LM",
          "model": "Phi-2-2B",
          "parallelism": "TP(8)+DP(4)",
          "source": "AutoCCL NSDI'25 evaluation"
        },
        "framework": "PyTorch + Megatron-LM",
        "gpu_type": null,
        "gpus_per_node": null,
        "model": "Phi-2-2B",
        "network": null,
        "nic_count": null,
        "nodes": 4,
        "scale": "32-gpu",
        "topology": "a40-pcie-8gpu",
        "workload": "autoccl-phi2-2b",
        "workload_kind": "training"
      },
      "created_at": "2026-02-02T18:56:35.621309Z",
      "metrics": {
        "algbw_gbps": 90.0,
        "busbw_gbps": 79.2,
        "comm_time_ms": 544.5,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 1210.0,
        "loss": null,
        "raw": {
          "seed": 1582140,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": 5242880,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 192,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {
          "category": "llm",
          "cluster": "4-node, 32xA40, PCIe intra, 100Gbps IB",
          "collectives": [
            "AllGather",
            "ReduceScatter",
            "AllReduce"
          ],
          "framework": "PyTorch + Megatron-LM",
          "model": "Phi-2-2B",
          "parallelism": "TP(8)+DP(4)",
          "source": "AutoCCL NSDI'25 evaluation"
        },
        "framework": "PyTorch + Megatron-LM",
        "gpu_type": null,
        "gpus_per_node": null,
        "model": "Phi-2-2B",
        "network": null,
        "nic_count": null,
        "nodes": 4,
        "scale": "32-gpu",
        "topology": "a40-pcie-8gpu",
        "workload": "autoccl-phi2-2b",
        "workload_kind": "training"
      },
      "created_at": "2026-02-02T18:56:35.621345Z",
      "metrics": {
        "algbw_gbps": 95.0,
        "busbw_gbps": 83.6,
        "comm_time_ms": 543.375,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 1207.5,
        "loss": null,
        "raw": {
          "seed": 8654045,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": 6291456,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 192,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL128",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {
          "category": "llm",
          "cluster": "4-node, 32xA40, PCIe intra, 100Gbps IB",
          "collectives": [
            "AllGather",
            "ReduceScatter",
            "AllReduce"
          ],
          "framework": "PyTorch + Megatron-LM",
          "model": "Phi-2-2B",
          "parallelism": "TP(8)+DP(4)",
          "source": "AutoCCL NSDI'25 evaluation"
        },
        "framework": "PyTorch + Megatron-LM",
        "gpu_type": null,
        "gpus_per_node": null,
        "model": "Phi-2-2B",
        "network": null,
        "nic_count": null,
        "nodes": 4,
        "scale": "32-gpu",
        "topology": "a40-pcie-8gpu",
        "workload": "autoccl-phi2-2b",
        "workload_kind": "training"
      },
      "created_at": "2026-02-02T18:56:35.621383Z",
      "metrics": {
        "algbw_gbps": 113.0,
        "busbw_gbps": 99.44,
        "comm_time_ms": 534.375,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 1187.5,
        "loss": null,
        "raw": {
          "seed": 193043,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": 6291456,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 192,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {
          "category": "llm",
          "cluster": "4-node, 32xA40, PCIe intra, 100Gbps IB",
          "collectives": [
            "AllGather",
            "ReduceScatter",
            "AllReduce"
          ],
          "framework": "PyTorch + Megatron-LM",
          "model": "Phi-2-2B",
          "parallelism": "TP(8)+DP(4)",
          "source": "AutoCCL NSDI'25 evaluation"
        },
        "framework": "PyTorch + Megatron-LM",
        "gpu_type": null,
        "gpus_per_node": null,
        "model": "Phi-2-2B",
        "network": null,
        "nic_count": null,
        "nodes": 4,
        "scale": "32-gpu",
        "topology": "a40-pcie-8gpu",
        "workload": "autoccl-phi2-2b",
        "workload_kind": "training"
      },
      "created_at": "2026-02-02T18:56:35.621419Z",
      "metrics": {
        "algbw_gbps": 114.0,
        "busbw_gbps": 100.32000000000001,
        "comm_time_ms": 483.75,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 1075.0,
        "loss": null,
        "raw": {
          "seed": 8993604,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": 4194304,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 192,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {
          "category": "llm",
          "cluster": "4-node, 32xA40, PCIe intra, 100Gbps IB",
          "collectives": [
            "AllGather",
            "ReduceScatter",
            "AllReduce"
          ],
          "framework": "PyTorch + Megatron-LM",
          "model": "Phi-2-2B",
          "parallelism": "TP(8)+DP(4)",
          "source": "AutoCCL NSDI'25 evaluation"
        },
        "framework": "PyTorch + Megatron-LM",
        "gpu_type": null,
        "gpus_per_node": null,
        "model": "Phi-2-2B",
        "network": null,
        "nic_count": null,
        "nodes": 4,
        "scale": "32-gpu",
        "topology": "a40-pcie-8gpu",
        "workload": "autoccl-phi2-2b",
        "workload_kind": "training"
      },
      "created_at": "2026-02-02T18:58:59.353792Z",
      "metrics": {
        "algbw_gbps": 117.0,
        "busbw_gbps": 102.96,
        "comm_time_ms": 586.125,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 1302.5,
        "loss": null,
        "raw": {
          "seed": 6306147,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": 4194304,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 256,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {
          "category": "llm",
          "cluster": "4-node, 32xA40, PCIe intra, 100Gbps IB",
          "collectives": [
            "AllGather",
            "ReduceScatter",
            "AllReduce"
          ],
          "framework": "PyTorch + Megatron-LM",
          "model": "Phi-2-2B",
          "parallelism": "TP(8)+DP(4)",
          "source": "AutoCCL NSDI'25 evaluation"
        },
        "framework": "PyTorch + Megatron-LM",
        "gpu_type": null,
        "gpus_per_node": null,
        "model": "Phi-2-2B",
        "network": null,
        "nic_count": null,
        "nodes": 4,
        "scale": "32-gpu",
        "topology": "a40-pcie-8gpu",
        "workload": "autoccl-phi2-2b",
        "workload_kind": "training"
      },
      "created_at": "2026-02-02T18:58:59.353826Z",
      "metrics": {
        "algbw_gbps": 100.0,
        "busbw_gbps": 88.0,
        "comm_time_ms": 627.75,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 1395.0,
        "loss": null,
        "raw": {
          "seed": 3367090,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": 4194304,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 192,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {
          "category": "llm",
          "cluster": "4-node, 32xA40, PCIe intra, 100Gbps IB",
          "collectives": [
            "AllGather",
            "ReduceScatter",
            "AllReduce"
          ],
          "framework": "PyTorch + Megatron-LM",
          "model": "Phi-2-2B",
          "parallelism": "TP(8)+DP(4)",
          "source": "AutoCCL NSDI'25 evaluation"
        },
        "framework": "PyTorch + Megatron-LM",
        "gpu_type": null,
        "gpus_per_node": null,
        "model": "Phi-2-2B",
        "network": null,
        "nic_count": null,
        "nodes": 4,
        "scale": "32-gpu",
        "topology": "a40-pcie-8gpu",
        "workload": "autoccl-phi2-2b",
        "workload_kind": "training"
      },
      "created_at": "2026-02-02T18:58:59.353858Z",
      "metrics": {
        "algbw_gbps": 117.0,
        "busbw_gbps": 102.96,
        "comm_time_ms": 572.625,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 1272.5,
        "loss": null,
        "raw": {
          "seed": 6306147,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": 5242880,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 192,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {
          "category": "llm",
          "cluster": "4-node, 32xA40, PCIe intra, 100Gbps IB",
          "collectives": [
            "AllGather",
            "ReduceScatter",
            "AllReduce"
          ],
          "framework": "PyTorch + Megatron-LM",
          "model": "Phi-2-2B",
          "parallelism": "TP(8)+DP(4)",
          "source": "AutoCCL NSDI'25 evaluation"
        },
        "framework": "PyTorch + Megatron-LM",
        "gpu_type": null,
        "gpus_per_node": null,
        "model": "Phi-2-2B",
        "network": null,
        "nic_count": null,
        "nodes": 4,
        "scale": "32-gpu",
        "topology": "a40-pcie-8gpu",
        "workload": "autoccl-phi2-2b",
        "workload_kind": "training"
      },
      "created_at": "2026-02-02T18:58:59.353893Z",
      "metrics": {
        "algbw_gbps": 95.0,
        "busbw_gbps": 83.6,
        "comm_time_ms": 563.625,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 1252.5,
        "loss": null,
        "raw": {
          "seed": 8654045,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": 5242880,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 192,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {
          "category": "llm",
          "cluster": "4-node, 32xA40, PCIe intra, 100Gbps IB",
          "collectives": [
            "AllGather",
            "ReduceScatter",
            "AllReduce"
          ],
          "framework": "PyTorch + Megatron-LM",
          "model": "Phi-2-2B",
          "parallelism": "TP(8)+DP(4)",
          "source": "AutoCCL NSDI'25 evaluation"
        },
        "framework": "PyTorch + Megatron-LM",
        "gpu_type": null,
        "gpus_per_node": null,
        "model": "Phi-2-2B",
        "network": null,
        "nic_count": null,
        "nodes": 4,
        "scale": "32-gpu",
        "topology": "a40-pcie-8gpu",
        "workload": "autoccl-phi2-2b",
        "workload_kind": "training"
      },
      "created_at": "2026-02-02T18:58:59.353923Z",
      "metrics": {
        "algbw_gbps": 95.0,
        "busbw_gbps": 83.6,
        "comm_time_ms": 556.875,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 1237.5,
        "loss": null,
        "raw": {
          "seed": 8654045,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": 5242880,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 256,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL128",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {
          "category": "llm",
          "cluster": "4-node, 32xA40, PCIe intra, 100Gbps IB",
          "collectives": [
            "AllGather",
            "ReduceScatter",
            "AllReduce"
          ],
          "framework": "PyTorch + Megatron-LM",
          "model": "Phi-2-2B",
          "parallelism": "TP(8)+DP(4)",
          "source": "AutoCCL NSDI'25 evaluation"
        },
        "framework": "PyTorch + Megatron-LM",
        "gpu_type": null,
        "gpus_per_node": null,
        "model": "Phi-2-2B",
        "network": null,
        "nic_count": null,
        "nodes": 4,
        "scale": "32-gpu",
        "topology": "a40-pcie-8gpu",
        "workload": "autoccl-phi2-2b",
        "workload_kind": "training"
      },
      "created_at": "2026-02-02T18:58:59.353952Z",
      "metrics": {
        "algbw_gbps": 144.0,
        "busbw_gbps": 126.72,
        "comm_time_ms": 515.2499999999999,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 1144.9999999999998,
        "loss": null,
        "raw": {
          "seed": 15787014,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": 5242880,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 192,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {
          "category": "llm",
          "cluster": "4-node, 32xA40, PCIe intra, 100Gbps IB",
          "collectives": [
            "AllGather",
            "ReduceScatter",
            "AllReduce"
          ],
          "framework": "PyTorch + Megatron-LM",
          "model": "Phi-2-2B",
          "parallelism": "TP(8)+DP(4)",
          "source": "AutoCCL NSDI'25 evaluation"
        },
        "framework": "PyTorch + Megatron-LM",
        "gpu_type": null,
        "gpus_per_node": null,
        "model": "Phi-2-2B",
        "network": null,
        "nic_count": null,
        "nodes": 4,
        "scale": "32-gpu",
        "topology": "a40-pcie-8gpu",
        "workload": "autoccl-phi2-2b",
        "workload_kind": "training"
      },
      "created_at": "2026-02-02T18:58:59.353981Z",
      "metrics": {
        "algbw_gbps": 95.0,
        "busbw_gbps": 83.6,
        "comm_time_ms": 543.375,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 1207.5,
        "loss": null,
        "raw": {
          "seed": 8654045,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": 4194304,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 192,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL128",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {
          "category": "llm",
          "cluster": "4-node, 32xA40, PCIe intra, 100Gbps IB",
          "collectives": [
            "AllGather",
            "ReduceScatter",
            "AllReduce"
          ],
          "framework": "PyTorch + Megatron-LM",
          "model": "Phi-2-2B",
          "parallelism": "TP(8)+DP(4)",
          "source": "AutoCCL NSDI'25 evaluation"
        },
        "framework": "PyTorch + Megatron-LM",
        "gpu_type": null,
        "gpus_per_node": null,
        "model": "Phi-2-2B",
        "network": null,
        "nic_count": null,
        "nodes": 4,
        "scale": "32-gpu",
        "topology": "a40-pcie-8gpu",
        "workload": "autoccl-phi2-2b",
        "workload_kind": "training"
      },
      "created_at": "2026-02-02T18:58:59.354010Z",
      "metrics": {
        "algbw_gbps": 95.0,
        "busbw_gbps": 83.6,
        "comm_time_ms": 559.1250000000001,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 1242.5000000000002,
        "loss": null,
        "raw": {
          "seed": 3620465,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": 4194304,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 192,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {
          "category": "llm",
          "cluster": "4-node, 32xA40, PCIe intra, 100Gbps IB",
          "collectives": [
            "AllGather",
            "ReduceScatter",
            "AllReduce"
          ],
          "framework": "PyTorch + Megatron-LM",
          "model": "Phi-2-2B",
          "parallelism": "TP(8)+DP(4)",
          "source": "AutoCCL NSDI'25 evaluation"
        },
        "framework": "PyTorch + Megatron-LM",
        "gpu_type": null,
        "gpus_per_node": null,
        "model": "Phi-2-2B",
        "network": null,
        "nic_count": null,
        "nodes": 4,
        "scale": "32-gpu",
        "topology": "a40-pcie-8gpu",
        "workload": "autoccl-phi2-2b",
        "workload_kind": "training"
      },
      "created_at": "2026-02-02T18:58:59.354038Z",
      "metrics": {
        "algbw_gbps": 117.0,
        "busbw_gbps": 102.96,
        "comm_time_ms": 532.125,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 1182.4999999999998,
        "loss": null,
        "raw": {
          "seed": 6306147,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": 4194304,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 192,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {
          "category": "llm",
          "cluster": "4-node, 32xA40, PCIe intra, 100Gbps IB",
          "collectives": [
            "AllGather",
            "ReduceScatter",
            "AllReduce"
          ],
          "framework": "PyTorch + Megatron-LM",
          "model": "Phi-2-2B",
          "parallelism": "TP(8)+DP(4)",
          "source": "AutoCCL NSDI'25 evaluation"
        },
        "framework": "PyTorch + Megatron-LM",
        "gpu_type": null,
        "gpus_per_node": null,
        "model": "Phi-2-2B",
        "network": null,
        "nic_count": null,
        "nodes": 4,
        "scale": "32-gpu",
        "topology": "a40-pcie-8gpu",
        "workload": "autoccl-phi2-2b",
        "workload_kind": "training"
      },
      "created_at": "2026-02-02T19:00:04.779131Z",
      "metrics": {
        "algbw_gbps": 117.0,
        "busbw_gbps": 102.96,
        "comm_time_ms": 586.125,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 1302.5,
        "loss": null,
        "raw": {
          "seed": 6306147,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": 4194304,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 256,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {
          "category": "llm",
          "cluster": "4-node, 32xA40, PCIe intra, 100Gbps IB",
          "collectives": [
            "AllGather",
            "ReduceScatter",
            "AllReduce"
          ],
          "framework": "PyTorch + Megatron-LM",
          "model": "Phi-2-2B",
          "parallelism": "TP(8)+DP(4)",
          "source": "AutoCCL NSDI'25 evaluation"
        },
        "framework": "PyTorch + Megatron-LM",
        "gpu_type": null,
        "gpus_per_node": null,
        "model": "Phi-2-2B",
        "network": null,
        "nic_count": null,
        "nodes": 4,
        "scale": "32-gpu",
        "topology": "a40-pcie-8gpu",
        "workload": "autoccl-phi2-2b",
        "workload_kind": "training"
      },
      "created_at": "2026-02-02T19:00:04.779174Z",
      "metrics": {
        "algbw_gbps": 100.0,
        "busbw_gbps": 88.0,
        "comm_time_ms": 627.75,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 1395.0,
        "loss": null,
        "raw": {
          "seed": 3367090,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": 4194304,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 192,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {
          "category": "llm",
          "cluster": "4-node, 32xA40, PCIe intra, 100Gbps IB",
          "collectives": [
            "AllGather",
            "ReduceScatter",
            "AllReduce"
          ],
          "framework": "PyTorch + Megatron-LM",
          "model": "Phi-2-2B",
          "parallelism": "TP(8)+DP(4)",
          "source": "AutoCCL NSDI'25 evaluation"
        },
        "framework": "PyTorch + Megatron-LM",
        "gpu_type": null,
        "gpus_per_node": null,
        "model": "Phi-2-2B",
        "network": null,
        "nic_count": null,
        "nodes": 4,
        "scale": "32-gpu",
        "topology": "a40-pcie-8gpu",
        "workload": "autoccl-phi2-2b",
        "workload_kind": "training"
      },
      "created_at": "2026-02-02T19:00:04.779212Z",
      "metrics": {
        "algbw_gbps": 117.0,
        "busbw_gbps": 102.96,
        "comm_time_ms": 572.625,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 1272.5,
        "loss": null,
        "raw": {
          "seed": 6306147,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": 3145728,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 192,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {
          "category": "llm",
          "cluster": "4-node, 32xA40, PCIe intra, 100Gbps IB",
          "collectives": [
            "AllGather",
            "ReduceScatter",
            "AllReduce"
          ],
          "framework": "PyTorch + Megatron-LM",
          "model": "Phi-2-2B",
          "parallelism": "TP(8)+DP(4)",
          "source": "AutoCCL NSDI'25 evaluation"
        },
        "framework": "PyTorch + Megatron-LM",
        "gpu_type": null,
        "gpus_per_node": null,
        "model": "Phi-2-2B",
        "network": null,
        "nic_count": null,
        "nodes": 4,
        "scale": "32-gpu",
        "topology": "a40-pcie-8gpu",
        "workload": "autoccl-phi2-2b",
        "workload_kind": "training"
      },
      "created_at": "2026-02-02T19:00:04.779248Z",
      "metrics": {
        "algbw_gbps": 145.0,
        "busbw_gbps": 127.6,
        "comm_time_ms": 574.8749999999999,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 1277.4999999999998,
        "loss": null,
        "raw": {
          "seed": 4875955,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": 3145728,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 192,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {
          "category": "llm",
          "cluster": "4-node, 32xA40, PCIe intra, 100Gbps IB",
          "collectives": [
            "AllGather",
            "ReduceScatter",
            "AllReduce"
          ],
          "framework": "PyTorch + Megatron-LM",
          "model": "Phi-2-2B",
          "parallelism": "TP(8)+DP(4)",
          "source": "AutoCCL NSDI'25 evaluation"
        },
        "framework": "PyTorch + Megatron-LM",
        "gpu_type": null,
        "gpus_per_node": null,
        "model": "Phi-2-2B",
        "network": null,
        "nic_count": null,
        "nodes": 4,
        "scale": "32-gpu",
        "topology": "a40-pcie-8gpu",
        "workload": "autoccl-phi2-2b",
        "workload_kind": "training"
      },
      "created_at": "2026-02-02T19:00:04.779284Z",
      "metrics": {
        "algbw_gbps": 145.0,
        "busbw_gbps": 127.6,
        "comm_time_ms": 568.125,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 1262.5,
        "loss": null,
        "raw": {
          "seed": 4875955,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": 3145728,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 256,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL128",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {
          "category": "llm",
          "cluster": "4-node, 32xA40, PCIe intra, 100Gbps IB",
          "collectives": [
            "AllGather",
            "ReduceScatter",
            "AllReduce"
          ],
          "framework": "PyTorch + Megatron-LM",
          "model": "Phi-2-2B",
          "parallelism": "TP(8)+DP(4)",
          "source": "AutoCCL NSDI'25 evaluation"
        },
        "framework": "PyTorch + Megatron-LM",
        "gpu_type": null,
        "gpus_per_node": null,
        "model": "Phi-2-2B",
        "network": null,
        "nic_count": null,
        "nodes": 4,
        "scale": "32-gpu",
        "topology": "a40-pcie-8gpu",
        "workload": "autoccl-phi2-2b",
        "workload_kind": "training"
      },
      "created_at": "2026-02-02T19:00:04.779316Z",
      "metrics": {
        "algbw_gbps": 124.0,
        "busbw_gbps": 109.12,
        "comm_time_ms": 560.2499999999999,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 1244.9999999999998,
        "loss": null,
        "raw": {
          "seed": 15878554,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": 3145728,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 192,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {
          "category": "llm",
          "cluster": "4-node, 32xA40, PCIe intra, 100Gbps IB",
          "collectives": [
            "AllGather",
            "ReduceScatter",
            "AllReduce"
          ],
          "framework": "PyTorch + Megatron-LM",
          "model": "Phi-2-2B",
          "parallelism": "TP(8)+DP(4)",
          "source": "AutoCCL NSDI'25 evaluation"
        },
        "framework": "PyTorch + Megatron-LM",
        "gpu_type": null,
        "gpus_per_node": null,
        "model": "Phi-2-2B",
        "network": null,
        "nic_count": null,
        "nodes": 4,
        "scale": "32-gpu",
        "topology": "a40-pcie-8gpu",
        "workload": "autoccl-phi2-2b",
        "workload_kind": "training"
      },
      "created_at": "2026-02-02T19:00:04.779350Z",
      "metrics": {
        "algbw_gbps": 145.0,
        "busbw_gbps": 127.6,
        "comm_time_ms": 554.625,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 1232.5,
        "loss": null,
        "raw": {
          "seed": 4875955,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": 4194304,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 192,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL128",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {
          "category": "llm",
          "cluster": "4-node, 32xA40, PCIe intra, 100Gbps IB",
          "collectives": [
            "AllGather",
            "ReduceScatter",
            "AllReduce"
          ],
          "framework": "PyTorch + Megatron-LM",
          "model": "Phi-2-2B",
          "parallelism": "TP(8)+DP(4)",
          "source": "AutoCCL NSDI'25 evaluation"
        },
        "framework": "PyTorch + Megatron-LM",
        "gpu_type": null,
        "gpus_per_node": null,
        "model": "Phi-2-2B",
        "network": null,
        "nic_count": null,
        "nodes": 4,
        "scale": "32-gpu",
        "topology": "a40-pcie-8gpu",
        "workload": "autoccl-phi2-2b",
        "workload_kind": "training"
      },
      "created_at": "2026-02-02T19:00:04.779443Z",
      "metrics": {
        "algbw_gbps": 95.0,
        "busbw_gbps": 83.6,
        "comm_time_ms": 559.1250000000001,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 1242.5000000000002,
        "loss": null,
        "raw": {
          "seed": 3620465,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": 4194304,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 192,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {
          "category": "llm",
          "cluster": "4-node, 32xA40, PCIe intra, 100Gbps IB",
          "collectives": [
            "AllGather",
            "ReduceScatter",
            "AllReduce"
          ],
          "framework": "PyTorch + Megatron-LM",
          "model": "Phi-2-2B",
          "parallelism": "TP(8)+DP(4)",
          "source": "AutoCCL NSDI'25 evaluation"
        },
        "framework": "PyTorch + Megatron-LM",
        "gpu_type": null,
        "gpus_per_node": null,
        "model": "Phi-2-2B",
        "network": null,
        "nic_count": null,
        "nodes": 4,
        "scale": "32-gpu",
        "topology": "a40-pcie-8gpu",
        "workload": "autoccl-phi2-2b",
        "workload_kind": "training"
      },
      "created_at": "2026-02-02T19:00:04.779476Z",
      "metrics": {
        "algbw_gbps": 117.0,
        "busbw_gbps": 102.96,
        "comm_time_ms": 532.125,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 1182.4999999999998,
        "loss": null,
        "raw": {
          "seed": 6306147,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": "1024",
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 192,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {
          "category": "llm",
          "cluster": "4-node, 32xA40, PCIe intra, 100Gbps IB",
          "collectives": [
            "AllGather",
            "ReduceScatter",
            "AllReduce"
          ],
          "framework": "PyTorch + Megatron-LM",
          "model": "Phi-2-2B",
          "parallelism": "TP(8)+DP(4)",
          "source": "AutoCCL NSDI'25 evaluation"
        },
        "framework": "PyTorch + Megatron-LM",
        "gpu_type": null,
        "gpus_per_node": null,
        "model": "Phi-2-2B",
        "network": null,
        "nic_count": null,
        "nodes": 4,
        "scale": "32-gpu",
        "topology": "a40-pcie-8gpu",
        "workload": "autoccl-phi2-2b",
        "workload_kind": "training"
      },
      "created_at": "2026-02-02T19:01:05.228827Z",
      "metrics": {
        "algbw_gbps": 104.0,
        "busbw_gbps": 91.52,
        "comm_time_ms": 594.0000000000001,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 1320.0,
        "loss": null,
        "raw": {
          "seed": 8759954,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": "1024",
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 256,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {
          "category": "llm",
          "cluster": "4-node, 32xA40, PCIe intra, 100Gbps IB",
          "collectives": [
            "AllGather",
            "ReduceScatter",
            "AllReduce"
          ],
          "framework": "PyTorch + Megatron-LM",
          "model": "Phi-2-2B",
          "parallelism": "TP(8)+DP(4)",
          "source": "AutoCCL NSDI'25 evaluation"
        },
        "framework": "PyTorch + Megatron-LM",
        "gpu_type": null,
        "gpus_per_node": null,
        "model": "Phi-2-2B",
        "network": null,
        "nic_count": null,
        "nodes": 4,
        "scale": "32-gpu",
        "topology": "a40-pcie-8gpu",
        "workload": "autoccl-phi2-2b",
        "workload_kind": "training"
      },
      "created_at": "2026-02-02T19:01:05.228867Z",
      "metrics": {
        "algbw_gbps": 132.0,
        "busbw_gbps": 116.16,
        "comm_time_ms": 551.2499999999999,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 1224.9999999999998,
        "loss": null,
        "raw": {
          "seed": 576222,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": "1024",
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 192,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {
          "category": "llm",
          "cluster": "4-node, 32xA40, PCIe intra, 100Gbps IB",
          "collectives": [
            "AllGather",
            "ReduceScatter",
            "AllReduce"
          ],
          "framework": "PyTorch + Megatron-LM",
          "model": "Phi-2-2B",
          "parallelism": "TP(8)+DP(4)",
          "source": "AutoCCL NSDI'25 evaluation"
        },
        "framework": "PyTorch + Megatron-LM",
        "gpu_type": null,
        "gpus_per_node": null,
        "model": "Phi-2-2B",
        "network": null,
        "nic_count": null,
        "nodes": 4,
        "scale": "32-gpu",
        "topology": "a40-pcie-8gpu",
        "workload": "autoccl-phi2-2b",
        "workload_kind": "training"
      },
      "created_at": "2026-02-02T19:01:05.228900Z",
      "metrics": {
        "algbw_gbps": 104.0,
        "busbw_gbps": 91.52,
        "comm_time_ms": 580.5,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 1290.0,
        "loss": null,
        "raw": {
          "seed": 8759954,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": 1049600,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 192,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {
          "category": "llm",
          "cluster": "4-node, 32xA40, PCIe intra, 100Gbps IB",
          "collectives": [
            "AllGather",
            "ReduceScatter",
            "AllReduce"
          ],
          "framework": "PyTorch + Megatron-LM",
          "model": "Phi-2-2B",
          "parallelism": "TP(8)+DP(4)",
          "source": "AutoCCL NSDI'25 evaluation"
        },
        "framework": "PyTorch + Megatron-LM",
        "gpu_type": null,
        "gpus_per_node": null,
        "model": "Phi-2-2B",
        "network": null,
        "nic_count": null,
        "nodes": 4,
        "scale": "32-gpu",
        "topology": "a40-pcie-8gpu",
        "workload": "autoccl-phi2-2b",
        "workload_kind": "training"
      },
      "created_at": "2026-02-02T19:01:05.228933Z",
      "metrics": {
        "algbw_gbps": 93.0,
        "busbw_gbps": 81.84,
        "comm_time_ms": 561.375,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 1247.4999999999998,
        "loss": null,
        "raw": {
          "seed": 1414443,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": 1049600,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 192,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {
          "category": "llm",
          "cluster": "4-node, 32xA40, PCIe intra, 100Gbps IB",
          "collectives": [
            "AllGather",
            "ReduceScatter",
            "AllReduce"
          ],
          "framework": "PyTorch + Megatron-LM",
          "model": "Phi-2-2B",
          "parallelism": "TP(8)+DP(4)",
          "source": "AutoCCL NSDI'25 evaluation"
        },
        "framework": "PyTorch + Megatron-LM",
        "gpu_type": null,
        "gpus_per_node": null,
        "model": "Phi-2-2B",
        "network": null,
        "nic_count": null,
        "nodes": 4,
        "scale": "32-gpu",
        "topology": "a40-pcie-8gpu",
        "workload": "autoccl-phi2-2b",
        "workload_kind": "training"
      },
      "created_at": "2026-02-02T19:01:05.228969Z",
      "metrics": {
        "algbw_gbps": 93.0,
        "busbw_gbps": 81.84,
        "comm_time_ms": 554.625,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 1232.5,
        "loss": null,
        "raw": {
          "seed": 1414443,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "RING",
        "NCCL_BUFFSIZE": 4194304,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 256,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "SIMPLE",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {
          "category": "llm",
          "cluster": "4-node, 32xA40, PCIe intra, 100Gbps IB",
          "collectives": [
            "AllGather",
            "ReduceScatter",
            "AllReduce"
          ],
          "framework": "PyTorch + Megatron-LM",
          "model": "Phi-2-2B",
          "parallelism": "TP(8)+DP(4)",
          "source": "AutoCCL NSDI'25 evaluation"
        },
        "framework": "PyTorch + Megatron-LM",
        "gpu_type": null,
        "gpus_per_node": null,
        "model": "Phi-2-2B",
        "network": null,
        "nic_count": null,
        "nodes": 4,
        "scale": "32-gpu",
        "topology": "a40-pcie-8gpu",
        "workload": "autoccl-phi2-2b",
        "workload_kind": "training"
      },
      "created_at": "2026-02-02T19:03:41.453845Z",
      "metrics": {
        "algbw_gbps": 148.0,
        "busbw_gbps": 130.24,
        "comm_time_ms": 576.0000000000001,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 1280.0,
        "loss": null,
        "raw": {
          "seed": 12978238,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": 4194304,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 320,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {
          "category": "llm",
          "cluster": "4-node, 32xA40, PCIe intra, 100Gbps IB",
          "collectives": [
            "AllGather",
            "ReduceScatter",
            "AllReduce"
          ],
          "framework": "PyTorch + Megatron-LM",
          "model": "Phi-2-2B",
          "parallelism": "TP(8)+DP(4)",
          "source": "AutoCCL NSDI'25 evaluation"
        },
        "framework": "PyTorch + Megatron-LM",
        "gpu_type": null,
        "gpus_per_node": null,
        "model": "Phi-2-2B",
        "network": null,
        "nic_count": null,
        "nodes": 4,
        "scale": "32-gpu",
        "topology": "a40-pcie-8gpu",
        "workload": "autoccl-phi2-2b",
        "workload_kind": "training"
      },
      "created_at": "2026-02-02T19:03:41.453899Z",
      "metrics": {
        "algbw_gbps": 139.0,
        "busbw_gbps": 122.32000000000001,
        "comm_time_ms": 604.125,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 1342.5,
        "loss": null,
        "raw": {
          "seed": 12953869,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": 4194304,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 256,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {
          "category": "llm",
          "cluster": "4-node, 32xA40, PCIe intra, 100Gbps IB",
          "collectives": [
            "AllGather",
            "ReduceScatter",
            "AllReduce"
          ],
          "framework": "PyTorch + Megatron-LM",
          "model": "Phi-2-2B",
          "parallelism": "TP(8)+DP(4)",
          "source": "AutoCCL NSDI'25 evaluation"
        },
        "framework": "PyTorch + Megatron-LM",
        "gpu_type": null,
        "gpus_per_node": null,
        "model": "Phi-2-2B",
        "network": null,
        "nic_count": null,
        "nodes": 4,
        "scale": "32-gpu",
        "topology": "a40-pcie-8gpu",
        "workload": "autoccl-phi2-2b",
        "workload_kind": "training"
      },
      "created_at": "2026-02-02T19:03:41.453947Z",
      "metrics": {
        "algbw_gbps": 100.0,
        "busbw_gbps": 88.0,
        "comm_time_ms": 621.0000000000001,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 1380.0000000000002,
        "loss": null,
        "raw": {
          "seed": 3367090,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": 5242880,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 256,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {
          "category": "llm",
          "cluster": "4-node, 32xA40, PCIe intra, 100Gbps IB",
          "collectives": [
            "AllGather",
            "ReduceScatter",
            "AllReduce"
          ],
          "framework": "PyTorch + Megatron-LM",
          "model": "Phi-2-2B",
          "parallelism": "TP(8)+DP(4)",
          "source": "AutoCCL NSDI'25 evaluation"
        },
        "framework": "PyTorch + Megatron-LM",
        "gpu_type": null,
        "gpus_per_node": null,
        "model": "Phi-2-2B",
        "network": null,
        "nic_count": null,
        "nodes": 4,
        "scale": "32-gpu",
        "topology": "a40-pcie-8gpu",
        "workload": "autoccl-phi2-2b",
        "workload_kind": "training"
      },
      "created_at": "2026-02-02T19:03:41.453994Z",
      "metrics": {
        "algbw_gbps": 133.0,
        "busbw_gbps": 117.04,
        "comm_time_ms": 583.8749999999999,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 1297.4999999999998,
        "loss": null,
        "raw": {
          "seed": 1390663,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "RING",
        "NCCL_BUFFSIZE": 4194304,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 256,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "SIMPLE",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {
          "category": "llm",
          "cluster": "4-node, 32xA40, PCIe intra, 100Gbps IB",
          "collectives": [
            "AllGather",
            "ReduceScatter",
            "AllReduce"
          ],
          "framework": "PyTorch + Megatron-LM",
          "model": "Phi-2-2B",
          "parallelism": "TP(8)+DP(4)",
          "source": "AutoCCL NSDI'25 evaluation"
        },
        "framework": "PyTorch + Megatron-LM",
        "gpu_type": null,
        "gpus_per_node": null,
        "model": "Phi-2-2B",
        "network": null,
        "nic_count": null,
        "nodes": 4,
        "scale": "32-gpu",
        "topology": "a40-pcie-8gpu",
        "workload": "autoccl-phi2-2b",
        "workload_kind": "training"
      },
      "created_at": "2026-02-02T19:03:49.905530Z",
      "metrics": {
        "algbw_gbps": 148.0,
        "busbw_gbps": 130.24,
        "comm_time_ms": 576.0000000000001,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 1280.0,
        "loss": null,
        "raw": {
          "seed": 12978238,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": 4194304,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 320,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {
          "category": "llm",
          "cluster": "4-node, 32xA40, PCIe intra, 100Gbps IB",
          "collectives": [
            "AllGather",
            "ReduceScatter",
            "AllReduce"
          ],
          "framework": "PyTorch + Megatron-LM",
          "model": "Phi-2-2B",
          "parallelism": "TP(8)+DP(4)",
          "source": "AutoCCL NSDI'25 evaluation"
        },
        "framework": "PyTorch + Megatron-LM",
        "gpu_type": null,
        "gpus_per_node": null,
        "model": "Phi-2-2B",
        "network": null,
        "nic_count": null,
        "nodes": 4,
        "scale": "32-gpu",
        "topology": "a40-pcie-8gpu",
        "workload": "autoccl-phi2-2b",
        "workload_kind": "training"
      },
      "created_at": "2026-02-02T19:03:49.905586Z",
      "metrics": {
        "algbw_gbps": 139.0,
        "busbw_gbps": 122.32000000000001,
        "comm_time_ms": 604.125,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 1342.5,
        "loss": null,
        "raw": {
          "seed": 12953869,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": 4194304,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 256,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {
          "category": "llm",
          "cluster": "4-node, 32xA40, PCIe intra, 100Gbps IB",
          "collectives": [
            "AllGather",
            "ReduceScatter",
            "AllReduce"
          ],
          "framework": "PyTorch + Megatron-LM",
          "model": "Phi-2-2B",
          "parallelism": "TP(8)+DP(4)",
          "source": "AutoCCL NSDI'25 evaluation"
        },
        "framework": "PyTorch + Megatron-LM",
        "gpu_type": null,
        "gpus_per_node": null,
        "model": "Phi-2-2B",
        "network": null,
        "nic_count": null,
        "nodes": 4,
        "scale": "32-gpu",
        "topology": "a40-pcie-8gpu",
        "workload": "autoccl-phi2-2b",
        "workload_kind": "training"
      },
      "created_at": "2026-02-02T19:03:49.905614Z",
      "metrics": {
        "algbw_gbps": 100.0,
        "busbw_gbps": 88.0,
        "comm_time_ms": 621.0000000000001,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 1380.0000000000002,
        "loss": null,
        "raw": {
          "seed": 3367090,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    },
    {
      "config": {
        "NCCL_ALGO": "TREE",
        "NCCL_BUFFSIZE": 5242880,
        "NCCL_IB_QPS_PER_CONNECTION": 1,
        "NCCL_MAX_NCHANNELS": 8,
        "NCCL_MIN_NCHANNELS": 4,
        "NCCL_NET_GDR_LEVEL": 1,
        "NCCL_NSOCKS_PERTHREAD": 2,
        "NCCL_NTHREADS": 256,
        "NCCL_P2P_LEVEL": "SYS",
        "NCCL_PROTO": "LL",
        "NCCL_SHM_DISABLE": false,
        "NCCL_SOCKET_NTHREADS": 2
      },
      "context": {
        "extra": {
          "category": "llm",
          "cluster": "4-node, 32xA40, PCIe intra, 100Gbps IB",
          "collectives": [
            "AllGather",
            "ReduceScatter",
            "AllReduce"
          ],
          "framework": "PyTorch + Megatron-LM",
          "model": "Phi-2-2B",
          "parallelism": "TP(8)+DP(4)",
          "source": "AutoCCL NSDI'25 evaluation"
        },
        "framework": "PyTorch + Megatron-LM",
        "gpu_type": null,
        "gpus_per_node": null,
        "model": "Phi-2-2B",
        "network": null,
        "nic_count": null,
        "nodes": 4,
        "scale": "32-gpu",
        "topology": "a40-pcie-8gpu",
        "workload": "autoccl-phi2-2b",
        "workload_kind": "training"
      },
      "created_at": "2026-02-02T19:03:49.905642Z",
      "metrics": {
        "algbw_gbps": 133.0,
        "busbw_gbps": 117.04,
        "comm_time_ms": 583.8749999999999,
        "error_budget": null,
        "failure_reason": null,
        "iteration_time_ms": 1297.4999999999998,
        "loss": null,
        "raw": {
          "seed": 1390663,
          "simulated": true,
          "sla_ok": true,
          "sla_rollback": false,
          "sla_severity": "soft",
          "sla_violations": []
        },
        "schema_version": "1.0",
        "success": true,
        "throughput": null
      }
    }
  ]
}
