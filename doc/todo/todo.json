```json
{
  "meta": {
    "project": "CCLAgent",
    "goal": "Perfection-grade implementation of the 3-phase design: Offline Planning (microbench + grounding) -> Online Tuning (hypothesis + numeric + real eval) -> Post-run Updating (rules + surrogate/model training) with safety/rollback and multi-node orchestration.",
    "constraints": {
      "preserve_existing_dry_run": true,
      "all_new_behavior_gated_by_config": true,
      "all_tool_runs_emit_artifacts": true,
      "no_silent_failures": true,
      "reproducibility_required": true
    },
    "run_artifacts_root": "artifacts/",
    "memory_root": "memory/",
    "rag_index_root_default": "rag_index/",
    "schema_versions": {
      "run_context": "1.0",
      "metrics": "1.0",
      "memory": "2.0",
      "initial_config_plan": "1.0",
      "tuning_step_record": "1.0",
      "rag_index": "1.0",
      "surrogate_model_meta": "1.0",
      "rule_record": "1.0",
      "avoid_rule_record": "1.0"
    }
  },
  "strict_execution_order": [
    "A1_run_context_artifacts",
    "A2_metrics_schema_enforcement",
    "A3_analyzer_refactor_core_loop",
    "B4_real_microbench_integration",
    "B5_initial_config_plan_object",
    "B6_rag_embeddings_index",
    "B7_memory_fuzzy_retrieval_decay",
    "C8_hypothesis_object_and_compile",
    "C9_numeric_search_manager_subspaces",
    "C10_real_batch_evaluation_short_runs",
    "C11_persisted_surrogate_uncertainty",
    "D12_risk_scoring_safe_envelope",
    "D13_rollback_and_avoid_rules",
    "E14_postrun_rule_distillation_with_evidence",
    "E15_dataset_export_and_surrogate_training",
    "E16_optional_export_sft_rl_datasets",
    "F17_launchers_slurm_mpi_torchrun",
    "F18_injob_ext_tuner_mode",
    "G19_expand_nccl_parameter_space",
    "G20_tests_and_ci_smoke"
  ],
  "stages": [
    {
      "stage_id": "A_foundations",
      "title": "Foundations: artifacts, metrics schema, analyzer refactor",
      "tasks": [
        {
          "task_id": "A1_run_context_artifacts",
          "title": "Add RunContext and artifacts plumbing",
          "priority": "P0",
          "dependencies": [],
          "files_to_modify": [
            "src/main.py",
            "src/types.py",
            "src/config.py",
            "src/agent/core.py"
          ],
          "files_to_add": [],
          "config_changes": {
            "AgentConfig": [
              "artifacts_root (default: artifacts/)",
              "seed (default: 0 or deterministic if unspecified)"
            ],
            "CLI": [
              "--artifacts-root",
              "--seed"
            ]
          },
          "implementation_steps": [
            "In src/types.py, add dataclass RunContext with fields: run_id, started_at_iso, artifacts_dir, dry_run, seed, git_commit(optional), host_info(dict), config_snapshot_path.",
            "In src/main.py, create run_id (uuid4), artifacts_dir = {artifacts_root}/{run_id}/, mkdir -p, write run_context.json (schema run_context 1.0).",
            "Persist a config snapshot JSON into artifacts_dir/config_snapshot.json (full resolved config).",
            "Thread RunContext into CCLAgent constructor and into ToolRegistry/build_tools so each tool can write artifacts.",
            "In src/agent/core.py ensure each tuning step writes artifacts/{run_id}/steps/step_{k}.json including chosen action, config hash, metrics path references."
          ],
          "artifacts_expected": [
            "artifacts/{run_id}/run_context.json",
            "artifacts/{run_id}/config_snapshot.json",
            "artifacts/{run_id}/steps/step_0.json (even in dry-run)"
          ],
          "verification": {
            "commands": [
              "python3 -m src.main --workload workload/autoccl/phi2-2b.json --dry-run --seed 123"
            ],
            "assertions": [
              "Artifacts directory created",
              "run_context.json exists and includes schema_version=1.0",
              "config_snapshot.json exists",
              "At least one step record exists"
            ]
          }
        },
        {
          "task_id": "A2_metrics_schema_enforcement",
          "title": "Standardize Metrics schema and enforce success/failure",
          "priority": "P0",
          "dependencies": [
            "A1_run_context_artifacts"
          ],
          "files_to_modify": [
            "src/types.py",
            "src/tools/metrics.py",
            "src/tools/workload.py",
            "src/tools/training.py",
            "src/tools/sla.py",
            "src/agent/executor.py"
          ],
          "files_to_add": [],
          "config_changes": {
            "AgentConfig": [
              "metrics.parse_mode (json_stdout_v1 | nccltests_v1 | autoccl_demo_v1)",
              "metrics.allow_missing_metrics (default false)"
            ],
            "WorkloadSpec": [
              "metrics_parser (optional)",
              "metrics_schema_version (default 1.0)"
            ]
          },
          "implementation_steps": [
            "In src/types.py, define Metrics schema with required fields: iteration_time_ms, success, failure_reason(optional), raw(dict), plus optional throughput, comm_time_ms, busbw_gbps, algbw_gbps, loss, error_budget. Include metrics_schema_version=1.0.",
            "Update MetricsCollector to support parse modes: json_stdout_v1 (strict JSON), nccltests_v1 (regex parse busbw/algbw/time), autoccl_demo_v1.",
            "In WorkloadRunner/TrainingJobRunner, always write: stdout.log, stderr.log, metrics.json to artifacts. If parsing fails and allow_missing_metrics=false -> Metrics.success=false with failure_reason and SLA sees as hard fail.",
            "Update SLA tool to accept Metrics and return SLAResult {ok, violations[], severity, rollback_recommended}.",
            "Update WorkloadExecutor to treat Metrics.success=false as failure and surface to analyzer."
          ],
          "artifacts_expected": [
            "artifacts/{run_id}/steps/step_{k}_stdout.log",
            "artifacts/{run_id}/steps/step_{k}_stderr.log",
            "artifacts/{run_id}/steps/step_{k}_metrics.json"
          ],
          "verification": {
            "commands": [
              "python3 -m src.main --workload workload/autoccl/phi2-2b.json --dry-run"
            ],
            "assertions": [
              "Each step has metrics.json with metrics_schema_version=1.0",
              "iteration_time_ms exists when success=true",
              "failure_reason exists when success=false"
            ]
          }
        },
        {
          "task_id": "A3_analyzer_refactor_core_loop",
          "title": "Create TuningAnalyzer and refactor core loop to call it exactly once per iteration",
          "priority": "P0",
          "dependencies": [
            "A2_metrics_schema_enforcement"
          ],
          "files_to_modify": [
            "src/agent/core.py",
            "src/agent/policy.py"
          ],
          "files_to_add": [
            "src/agent/analyzer.py"
          ],
          "config_changes": {
            "AgentConfig": [
              "plateau_eps",
              "plateau_patience",
              "target_gain (optional)",
              "stable_steps (optional)"
            ]
          },
          "implementation_steps": [
            "Add src/agent/analyzer.py with class TuningAnalyzer.plan_next_action(state, last_metrics, history, initial_plan)->TuningAction.",
            "Define strict decision order in analyzer: failure/SLA hard -> RollbackAction; budget exhausted -> StopAction; plateau -> StopAction or NumericSearchAction; else alternate hypothesis/numeric by budget.hypothesis_every.",
            "Refactor src/agent/core.py loop to: run executor -> collect metrics -> analyzer decides next action -> execute action. No other module may directly decide action type.",
            "Modify DecisionPolicy into strategy helpers called by analyzer (not owner of control flow).",
            "Persist analyzer decision artifact for each step with inputs summary and rationale."
          ],
          "artifacts_expected": [
            "artifacts/{run_id}/steps/step_{k}_decision.json"
          ],
          "verification": {
            "assertions": [
              "Exactly one decision artifact per step",
              "Decision artifact includes action_type and rationale",
              "Core loop no longer calls DecisionPolicy to decide action directly"
            ]
          }
        }
      ]
    },
    {
      "stage_id": "B_phase1_offline",
      "title": "Phase 1: real microbench + initial plan + embeddings RAG + fuzzy memory",
      "tasks": [
        {
          "task_id": "B4_real_microbench_integration",
          "title": "Implement real microbench runner (CCLInsight/nccltests modes) with strict JSON output schema",
          "priority": "P0",
          "dependencies": [
            "A3_analyzer_refactor_core_loop"
          ],
          "files_to_modify": [
            "src/tools/microbench.py",
            "src/types.py",
            "src/config.py",
            "src/agent/planner.py"
          ],
          "files_to_add": [
            "scripts/run_cclinsight_microbench.sh"
          ],
          "config_changes": {
            "AgentConfig": [
              "microbench.mode (dry|cclinsight|nccltests)",
              "microbench.command_template",
              "microbench.parse_schema (cclinsight_v1|nccltests_v1)",
              "microbench.timeout_sec",
              "microbench.repetitions",
              "microbench.env",
              "microbench.collect_topology"
            ]
          },
          "implementation_steps": [
            "In src/types.py add MicrobenchSignal, ImportantParam, and update MicrobenchResult to include important_params[], signals[], raw_path, command, runtime_sec.",
            "In src/tools/microbench.py implement run_real(): builds command from template, executes with timeout, writes stdout/stderr and raw JSON path to artifacts, parses strict JSON output into MicrobenchResult.",
            "Create scripts/run_cclinsight_microbench.sh wrapper that runs your microbench pipeline and prints a single JSON to stdout with keys: important_params[], signals[].",
            "In OfflinePlanner.offline_plan call MicrobenchRunner according to config; if real mode fails and allow_fallback=false -> abort; else fallback to dry-run with logged warning artifact.",
            "Write artifacts/{run_id}/offline/microbench_result.json."
          ],
          "artifacts_expected": [
            "artifacts/{run_id}/offline/microbench_stdout.log",
            "artifacts/{run_id}/offline/microbench_stderr.log",
            "artifacts/{run_id}/offline/microbench_result.json"
          ],
          "verification": {
            "assertions": [
              "Real microbench mode produces non-empty important_params",
              "MicrobenchResult includes command and runtime_sec",
              "If output is not valid JSON, tool fails with typed error (no silent parse)"
            ]
          }
        },
        {
          "task_id": "B5_initial_config_plan_object",
          "title": "Add explicit InitialConfigPlan (constraints + subspaces + ranked params) and persist it",
          "priority": "P0",
          "dependencies": [
            "B4_real_microbench_integration"
          ],
          "files_to_modify": [
            "src/types.py",
            "src/agent/planner.py"
          ],
          "files_to_add": [],
          "implementation_steps": [
            "In src/types.py add Subspace and InitialConfigPlan types (schema initial_config_plan 1.0).",
            "In OfflinePlanner.propose_initial_config replace implicit logic with: build InitialConfigPlan: baseline_config, constraints, important_params, candidate_subspaces, recommended_search_params, notes.",
            "Candidate_subspaces must implement 'implementation vs resource' split: fixed params (algo/proto/etc) and free params (channels/nthreads/buffsize/etc).",
            "Persist artifacts/{run_id}/offline/initial_plan.json and ensure Phase 2 consumes it."
          ],
          "artifacts_expected": [
            "artifacts/{run_id}/offline/initial_plan.json"
          ],
          "verification": {
            "assertions": [
              "initial_plan.json exists and includes candidate_subspaces[]",
              "recommended_search_params ordered and non-empty",
              "constraints include locked/free flags"
            ]
          }
        },
        {
          "task_id": "B6_rag_embeddings_index",
          "title": "Upgrade RAG from Jaccard to embeddings with on-disk index + ingestion script",
          "priority": "P1",
          "dependencies": [
            "B5_initial_config_plan_object"
          ],
          "files_to_modify": [
            "src/RAG/store.py",
            "src/agent/planner.py",
            "src/config.py",
            "src/types.py"
          ],
          "files_to_add": [
            "src/RAG/embeddings.py",
            "src/RAG/index.py",
            "scripts/build_rag_index.py"
          ],
          "config_changes": {
            "AgentConfig": [
              "rag.mode (jaccard|embeddings)",
              "rag.rebuild_index",
              "rag.index_path",
              "rag.top_k"
            ]
          },
          "implementation_steps": [
            "Refactor src/RAG/store.py into BaseRetriever interface plus JaccardRetriever (existing) and EmbeddingRetriever (new).",
            "Define RAGChunk type in src/types.py.",
            "Implement EmbeddingRetriever backed by on-disk index (chunks.jsonl + embeddings.npy + index_meta.json). Use local embeddings backend when available; otherwise TF-IDF fallback.",
            "Add scripts/build_rag_index.py: scans doc/Design, doc/Knowledge, README/workload docs; chunks; builds embeddings index at rag.index_path.",
            "Update planner to perform parameter-aware retrieval: query templates per important param and per interaction pair."
          ],
          "artifacts_expected": [
            "rag_index/index_meta.json",
            "rag_index/chunks.jsonl",
            "rag_index/embeddings.npy",
            "artifacts/{run_id}/offline/rag_queries.json"
          ],
          "verification": {
            "commands": [
              "python3 scripts/build_rag_index.py --docs doc/Design doc/Knowledge --out rag_index/"
            ],
            "assertions": [
              "Index files exist",
              "Planner retrieves top_k chunks for a param query in embeddings mode"
            ]
          }
        },
        {
          "task_id": "B7_memory_fuzzy_retrieval_decay",
          "title": "Upgrade memory: schema v2, fuzzy context matching, recency decay, win/try tracking, negative rules",
          "priority": "P0",
          "dependencies": [
            "B5_initial_config_plan_object"
          ],
          "files_to_modify": [
            "src/memory.py",
            "src/types.py",
            "src/config.py"
          ],
          "files_to_add": [
            "src/memory/index.py",
            "src/memory/schema.py"
          ],
          "config_changes": {
            "AgentConfig": [
              "memory.schema_version (default 2.0)",
              "memory.similarity_weights",
              "memory.half_life_days",
              "memory.top_k_rules"
            ]
          },
          "implementation_steps": [
            "Create memory schema v2.0: top-level schema_version=2.0, rules list with fields: condition(context signature), action(patch), confidence, wins, tries, last_used_iso, created_at_iso, evidence(record_ids). Include avoid_rules list.",
            "Implement MemoryStore.retrieve_rules(context, top_k): score each rule by context similarity and quality (wins/tries) and recency decay exp(-age/half_life).",
            "Update core loop: when a rule is applied, increment tries; if improvement, increment wins and confidence; if harms or failure, update avoid_rules candidate.",
            "Implement conflict handling: keep conflicting rules but reduce confidence and require online validation before promotion.",
            "Maintain backwards compatibility: if memory file is v1, migrate to v2 on load and write v2."
          ],
          "artifacts_expected": [
            "memory/agent_memory.json (schema_version 2.0)",
            "artifacts/{run_id}/offline/memory_retrieval.json"
          ],
          "verification": {
            "assertions": [
              "Rules can match approximately similar contexts (not exact match only)",
              "Rules track wins/tries and last_used",
              "Avoid rules are stored and retrievable"
            ]
          }
        }
      ]
    },
    {
      "stage_id": "C_phase2_online",
      "title": "Phase 2: hypothesis compilation, numeric search real eval, surrogate persistence",
      "tasks": [
        {
          "task_id": "C8_hypothesis_object_and_compile",
          "title": "Implement Hypothesis object + explicit compilation stage producing env + warnings + risk_score",
          "priority": "P0",
          "dependencies": [
            "B7_memory_fuzzy_retrieval_decay",
            "B6_rag_embeddings_index"
          ],
          "files_to_modify": [
            "src/types.py",
            "src/agent/policy.py",
            "src/tools/config_compiler.py",
            "src/tools/nccl.py",
            "src/agent/analyzer.py"
          ],
          "files_to_add": [],
          "implementation_steps": [
            "Add Hypothesis and CompiledConfig types in src/types.py.",
            "Split policy.py into HypothesisGenerator and NumericStrategy helpers used by analyzer.",
            "Implement HypothesisGenerator: uses memory rules (ranked), microbench important params, rag chunks, last metrics to propose one patch per hypothesis (limit major changes unless allowed).",
            "Upgrade ConfigCompiler.compile(): merges patch into base_config, validates ranges/types, emits env map, emits warnings for boundary values, produces risk_score placeholder (actual scorer in D12).",
            "Persist artifacts: step_{k}_hypothesis.json and step_{k}_compiled_config.json."
          ],
          "artifacts_expected": [
            "artifacts/{run_id}/steps/step_{k}_hypothesis.json",
            "artifacts/{run_id}/steps/step_{k}_compiled_config.json"
          ],
          "verification": {
            "assertions": [
              "Hypothesis always exists for hypothesis action",
              "Compilation always occurs before execution",
              "CompiledConfig includes env map and validation warnings"
            ]
          }
        },
        {
          "task_id": "C9_numeric_search_manager_subspaces",
          "title": "Implement NumericSearchManager with subspace-directed coordinate descent and persisted search state",
          "priority": "P0",
          "dependencies": [
            "B5_initial_config_plan_object",
            "C8_hypothesis_object_and_compile"
          ],
          "files_to_modify": [
            "src/types.py",
            "src/tools/numeric_search.py",
            "src/agent/analyzer.py",
            "src/agent/core.py"
          ],
          "files_to_add": [
            "src/search/coordinate_descent.py"
          ],
          "config_changes": {
            "AgentConfig": [
              "numeric.mode (predict_only|real_eval)",
              "numeric.batch_size",
              "numeric.concurrency",
              "numeric.max_evals_per_step",
              "numeric.subspace_max_steps"
            ]
          },
          "implementation_steps": [
            "Add SearchState type: current_subspace_idx, current_dim_idx, step_size, best_in_subspace, evaluated_hashes, history.",
            "Add NumericSearchManager that iterates InitialConfigPlan.candidate_subspaces and runs coordinate descent on free params.",
            "Update NumericSearchTool to accept candidates with evaluation_mode (predict_only|real_eval).",
            "Persist search state to artifacts/{run_id}/online/search_state.json each step for reproducibility."
          ],
          "artifacts_expected": [
            "artifacts/{run_id}/online/search_state.json",
            "artifacts/{run_id}/steps/step_{k}_candidates.json"
          ],
          "verification": {
            "assertions": [
              "Numeric step produces a candidate batch",
              "SearchState advances deterministically with fixed seed",
              "Candidate deduplication by config hash works"
            ]
          }
        },
        {
          "task_id": "C10_real_batch_evaluation_short_runs",
          "title": "Implement real evaluation for numeric candidates using short runs (batched, concurrent)",
          "priority": "P0",
          "dependencies": [
            "C9_numeric_search_manager_subspaces",
            "A2_metrics_schema_enforcement"
          ],
          "files_to_modify": [
            "src/types.py",
            "src/agent/executor.py",
            "src/tools/workload.py",
            "src/tools/training.py"
          ],
          "files_to_add": [],
          "config_changes": {
            "WorkloadSpec": [
              "eval_mode (full|short)",
              "eval_steps",
              "eval_timeout_sec"
            ]
          },
          "implementation_steps": [
            "Add run_batch(candidates, concurrency) to WorkloadExecutor. Each candidate: apply env/config, run workload in short mode, collect metrics, return ranked results.",
            "Implement short-run semantics: TrainingJobRunner must support early stop after eval_steps or timeout, and emit metrics.",
            "Ensure every candidate evaluation produces artifacts: candidate_i_stdout/stderr/metrics + summary ranking artifact."
          ],
          "artifacts_expected": [
            "artifacts/{run_id}/steps/step_{k}_batch_results.json",
            "artifacts/{run_id}/steps/step_{k}_candidate_{i}_metrics.json"
          ],
          "verification": {
            "assertions": [
              "Numeric real_eval mode actually invokes workload runner",
              "Batch results include ranking by objective metric",
              "Failures are captured per-candidate with failure_reason"
            ]
          }
        },
        {
          "task_id": "C11_persisted_surrogate_uncertainty",
          "title": "Replace kNN surrogate with persisted model + uncertainty; refit incrementally and reuse across runs",
          "priority": "P0",
          "dependencies": [
            "C10_real_batch_evaluation_short_runs",
            "B7_memory_fuzzy_retrieval_decay"
          ],
          "files_to_modify": [
            "src/agent/core.py",
            "src/config.py"
          ],
          "files_to_add": [
            "src/models/features.py",
            "src/models/surrogate.py"
          ],
          "config_changes": {
            "AgentConfig": [
              "surrogate.model_type (rf|gp|ensemble_rf)",
              "surrogate.refit_every_steps",
              "surrogate.dataset_path",
              "surrogate.model_dir"
            ]
          },
          "implementation_steps": [
            "Implement feature extraction: one-hot categorical, log-scale numeric, plus context features.",
            "Implement SurrogateModel interface: fit, predict (mean + uncertainty), save/load.",
            "Persist model to memory/models/surrogate_{context_hash}_{timestamp}.pkl and meta JSON.",
            "Update core loop: after each successful real eval, append record to dataset, refit on schedule, save model, and use uncertainty to pick exploratory candidates in numeric search."
          ],
          "artifacts_expected": [
            "memory/models/surrogate_{context_hash}_{timestamp}.pkl",
            "memory/models/surrogate_{context_hash}_{timestamp}.json",
            "artifacts/{run_id}/online/surrogate_predictions_step_{k}.json"
          ],
          "verification": {
            "assertions": [
              "Model persists across runs and loads next run",
              "Predictions include uncertainty",
              "Numeric search uses uncertainty to select at least some exploratory candidates (within safe bounds)"
            ]
          }
        }
      ]
    },
    {
      "stage_id": "D_safety",
      "title": "Safety: risk scoring, safe envelope, rollback and avoid rules",
      "tasks": [
        {
          "task_id": "D12_risk_scoring_safe_envelope",
          "title": "Implement RiskScorer and safe envelope constraints; integrate into compilation and candidate pruning",
          "priority": "P0",
          "dependencies": [
            "C8_hypothesis_object_and_compile",
            "C9_numeric_search_manager_subspaces"
          ],
          "files_to_modify": [
            "src/config.py",
            "src/tools/config_compiler.py",
            "src/agent/analyzer.py"
          ],
          "files_to_add": [
            "src/safety/risk.py"
          ],
          "config_changes": {
            "AgentConfig": [
              "safety.max_risk_score",
              "safety.safe_envelope (per-param hard bounds)",
              "safety.known_bad_combos_path (optional)"
            ]
          },
          "implementation_steps": [
            "Implement RiskScorer.score(config, context)->{risk_score, risk_level, reasons[]}.",
            "Apply safe envelope: enforce stricter bounds than parameter space when configured.",
            "Integrate into ConfigCompiler to attach risk_score and warnings.",
            "Integrate into numeric candidate pruning: drop candidates with risk_score > max_risk_score unless allow_high_risk=true."
          ],
          "artifacts_expected": [
            "artifacts/{run_id}/steps/step_{k}_risk.json"
          ],
          "verification": {
            "assertions": [
              "Risk score computed for every compiled config and numeric candidate",
              "Unsafe candidates are pruned when over threshold"
            ]
          }
        },
        {
          "task_id": "D13_rollback_and_avoid_rules",
          "title": "Implement rollback strategy and avoid-rule generation on failures and hard SLA violations",
          "priority": "P0",
          "dependencies": [
            "D12_risk_scoring_safe_envelope",
            "A2_metrics_schema_enforcement"
          ],
          "files_to_modify": [
            "src/agent/analyzer.py",
            "src/agent/core.py",
            "src/tools/sla.py",
            "src/memory.py"
          ],
          "files_to_add": [
            "src/safety/rollback.py"
          ],
          "implementation_steps": [
            "Maintain last_known_good_config in agent state; update only on successful runs meeting SLA.",
            "On hard SLA violation or Metrics.success=false: analyzer returns RollbackAction with target last_known_good_config.",
            "Write avoid rule candidate for the failed config patch (param deltas) with evidence.",
            "Decrement confidence or penalize rules/hypothesis that led to failure."
          ],
          "artifacts_expected": [
            "artifacts/{run_id}/steps/step_{k}_rollback.json",
            "memory/agent_memory.json (avoid_rules updated)"
          ],
          "verification": {
            "assertions": [
              "Rollback happens automatically and deterministically",
              "Avoid rules are stored with evidence linking to step record ids",
              "Agent continues after failure without crashing"
            ]
          }
        }
      ]
    },
    {
      "stage_id": "E_phase3_postrun",
      "title": "Phase 3: evidence-based rule distillation + dataset export + training",
      "tasks": [
        {
          "task_id": "E14_postrun_rule_distillation_with_evidence",
          "title": "Distill rules from tuning traces with evidence and confidence updates",
          "priority": "P0",
          "dependencies": [
            "C11_persisted_surrogate_uncertainty",
            "D13_rollback_and_avoid_rules"
          ],
          "files_to_modify": [
            "src/memory.py",
            "src/types.py",
            "src/agent/core.py"
          ],
          "files_to_add": [
            "src/agent/post_run.py"
          ],
          "implementation_steps": [
            "Create post_run module to process TuningRecords and compute per-param effect patterns.",
            "Generate rules: condition(context buckets + metric predicates) -> action(patch) with evidence(record_ids), avg_gain, variance.",
            "Update MemoryStore with new rules or merges; handle conflicts by lowering confidence or keeping alternates.",
            "Persist artifacts/{run_id}/postrun/rule_updates.json."
          ],
          "artifacts_expected": [
            "artifacts/{run_id}/postrun/rule_updates.json",
            "memory/agent_memory.json (rules updated with evidence, wins/tries)"
          ],
          "verification": {
            "assertions": [
              "Rules include evidence record ids and confidence",
              "Conflicts do not overwrite silently; confidence adjusted"
            ]
          }
        },
        {
          "task_id": "E15_dataset_export_and_surrogate_training",
          "title": "Export dataset per context and train/update surrogate models post-run with validation metrics",
          "priority": "P0",
          "dependencies": [
            "E14_postrun_rule_distillation_with_evidence"
          ],
          "files_to_modify": [
            "src/memory.py"
          ],
          "files_to_add": [
            "src/models/training.py",
            "scripts/train_surrogate.py"
          ],
          "implementation_steps": [
            "Export dataset to memory/datasets/{context_hash}.parquet (or jsonl) including config features, context features, metrics target(s), and step metadata.",
            "Train surrogate model (baseline RF ensemble) and compute validation error metrics (CV or holdout).",
            "Persist model and model_meta with training metrics and dataset fingerprint."
          ],
          "artifacts_expected": [
            "memory/datasets/{context_hash}.parquet",
            "memory/models/surrogate_{context_hash}_{timestamp}.pkl",
            "memory/models/surrogate_{context_hash}_{timestamp}.json"
          ],
          "verification": {
            "commands": [
              "python3 scripts/train_surrogate.py --dataset memory/datasets/{context_hash}.parquet --outdir memory/models/"
            ],
            "assertions": [
              "Training script runs and produces model + meta",
              "Meta includes validation metrics and feature schema version"
            ]
          }
        },
        {
          "task_id": "E16_optional_export_sft_rl_datasets",
          "title": "Optional: export SFT and RL datasets from traces (do not block core functionality)",
          "priority": "P2",
          "dependencies": [
            "E15_dataset_export_and_surrogate_training"
          ],
          "files_to_modify": [],
          "files_to_add": [
            "src/data/export.py",
            "scripts/export_sft_dataset.py",
            "scripts/export_rl_dataset.py"
          ],
          "implementation_steps": [
            "Export SFT pairs: input=context+rag+rules+metrics_history, output=next_action (hypothesis patch or numeric move).",
            "Export RL transitions: state=feature vector, action=config delta, reward=improvement in objective, done=stop/rollback.",
            "Version datasets and include schema metadata."
          ],
          "artifacts_expected": [
            "memory/datasets/sft_{timestamp}.jsonl",
            "memory/datasets/rl_{timestamp}.jsonl"
          ],
          "verification": {
            "assertions": [
              "Export scripts run and write schema metadata",
              "No changes to online tuning path are required to enable exports"
            ]
          }
        }
      ]
    },
    {
      "stage_id": "F_orchestration",
      "title": "Orchestration: multi-node launchers and in-job ext-tuner mode",
      "tasks": [
        {
          "task_id": "F17_launchers_slurm_mpi_torchrun",
          "title": "Add launchers for slurm/mpirun/torchrun with env propagation and log collection",
          "priority": "P1",
          "dependencies": [
            "A2_metrics_schema_enforcement"
          ],
          "files_to_modify": [
            "src/types.py",
            "src/tools/workload.py",
            "src/tools/training.py"
          ],
          "files_to_add": [
            "src/tools/launchers/slurm.py",
            "src/tools/launchers/mpi.py",
            "src/tools/launchers/torchrun.py"
          ],
          "config_changes": {
            "WorkloadSpec": [
              "launcher (local|torchrun|slurm|mpirun)",
              "launcher_args",
              "nodes",
              "gpus_per_node",
              "nnodes"
            ]
          },
          "implementation_steps": [
            "Implement launcher wrappers to build command lines and propagate env (compiled config + safety overrides).",
            "Add log collection strategy: at minimum rank0 stdout/stderr + aggregated stderr if possible.",
            "Detect cluster context from SLURM_* env variables when launcher=slurm."
          ],
          "artifacts_expected": [
            "artifacts/{run_id}/launch/launcher_plan.json",
            "artifacts/{run_id}/steps/step_{k}_rank0_stdout.log"
          ],
          "verification": {
            "assertions": [
              "Launcher selection is driven by WorkloadSpec",
              "Env precedence is respected",
              "Logs are captured under artifacts"
            ]
          }
        },
        {
          "task_id": "F18_injob_ext_tuner_mode",
          "title": "Implement in-job tuning via ExtTunerSession (single job run, iterative config fetch + metrics report)",
          "priority": "P1",
          "dependencies": [
            "D13_rollback_and_avoid_rules",
            "F17_launchers_slurm_mpi_torchrun"
          ],
          "files_to_modify": [
            "src/agent/ext_tuner.py",
            "src/agent/executor.py",
            "src/tools/ext_tuner.py"
          ],
          "files_to_add": [
            "src/tools/tuner_plugin_protocol.py",
            "scripts/ext_tuner_client.py"
          ],
          "config_changes": {
            "AgentConfig": [
              "execution_mode (restart_per_step|in_job_ext_tuner)",
              "ext_tuner.transport (file_rpc|unix_socket)",
              "ext_tuner.session_timeout_sec"
            ]
          },
          "implementation_steps": [
            "Define protocol: GET_CONFIG(task_id, step_idx, context) and REPORT_METRICS(task_id, step_idx, metrics).",
            "Implement ExtTunerSession server using selected transport. Persist session state under artifacts/{run_id}/ext_tuner/.",
            "Provide scripts/ext_tuner_client.py reference shim for workloads to call into agent between eval windows.",
            "Update WorkloadExecutor: if execution_mode=in_job_ext_tuner, start session server, launch job once, and drive tuning via protocol until stop, then keep running job with best config if workload supports it."
          ],
          "artifacts_expected": [
            "artifacts/{run_id}/ext_tuner/session_state.json",
            "artifacts/{run_id}/ext_tuner/rpc_log.jsonl"
          ],
          "verification": {
            "assertions": [
              "Single job launch can produce multiple tuning steps",
              "Agent returns configs and receives metrics without relaunching job",
              "Stop action ends tuning while job can continue on best config (when supported)"
            ]
          }
        }
      ]
    },
    {
      "stage_id": "G_hardening",
      "title": "Parameter space expansion, tests, CI smoke scripts",
      "tasks": [
        {
          "task_id": "G19_expand_nccl_parameter_space",
          "title": "Expand NCCL parameter space to include high-impact knobs and validate canonical env mapping",
          "priority": "P0",
          "dependencies": [
            "C8_hypothesis_object_and_compile"
          ],
          "files_to_modify": [
            "src/config.py",
            "src/types.py",
            "src/tools/nccl.py",
            "src/tools/config_compiler.py"
          ],
          "files_to_add": [],
          "implementation_steps": [
            "Add ParameterSpec entries for: NCCL_P2P_LEVEL, NCCL_NET_GDR_LEVEL, NCCL_SOCKET_NTHREADS, NCCL_NSOCKS_PERTHREAD, NCCL_IB_QPS_PER_CONNECTION, NCCL_SHM_DISABLE, plus ensure channels and existing params are correct.",
            "Ensure ConfigCompiler maps internal param names to correct env var names and types.",
            "Update validation to cover enums/ranges and safe envelope integration."
          ],
          "verification": {
            "assertions": [
              "ParameterSpace includes new params by default",
              "Compiler emits env vars for new params",
              "Invalid values are rejected with typed errors"
            ]
          }
        },
        {
          "task_id": "G20_tests_and_ci_smoke",
          "title": "Add unit tests, integration smoke scripts, and golden artifact schema checks",
          "priority": "P0",
          "dependencies": [
            "G19_expand_nccl_parameter_space",
            "E15_dataset_export_and_surrogate_training"
          ],
          "files_to_modify": [],
          "files_to_add": [
            "tests/test_config_validation.py",
            "tests/test_config_compiler_env.py",
            "tests/test_memory_retrieval_scoring.py",
            "tests/test_rag_retrieval.py",
            "tests/test_analyzer_action_selection.py",
            "tests/test_safety_risk_score.py",
            "scripts/ci_smoke_nccltests.sh",
            "scripts/ci_golden_artifacts.sh"
          ],
          "implementation_steps": [
            "Add pure-CPU unit tests with mocks for tool runners.",
            "Add smoke script for minimal nccl-tests parsing (optional GPU runner).",
            "Add golden artifact test: run dry-run with fixed seed and validate JSON schemas and required keys exist."
          ],
          "verification": {
            "commands": [
              "pytest -q",
              "bash scripts/ci_golden_artifacts.sh"
            ],
            "assertions": [
              "All unit tests pass",
              "Golden artifact schema checks pass"
            ]
          }
        }
      ]
    }
  ],
  "global_acceptance_criteria": {
    "offline_phase": [
      "Real microbench returns ranked important_params and signals (non-empty in real mode).",
      "Offline planner writes initial_plan.json with subspaces and constraints.",
      "Memory retrieval returns scored rules via fuzzy matching (not exact only).",
      "RAG embeddings retrieval returns top_k chunks for parameter-aware queries."
    ],
    "online_phase": [
      "Every step produces: decision.json, compiled_config.json (or candidate batch), final_env.json, metrics.json.",
      "Numeric step can run real_eval short runs and rank candidates by objective.",
      "Surrogate model persists across runs and predicts mean+uncertainty.",
      "Convergence logic stops on plateau or budget and records convergence report."
    ],
    "safety": [
      "Hard SLA violations or failures trigger rollback to last_known_good_config.",
      "Bad configs and harmful patches produce avoid rules with evidence."
    ],
    "post_run": [
      "Rules distilled with evidence (record_ids) and confidence updates.",
      "Dataset exported per context and surrogate training updates model + meta."
    ],
    "orchestration": [
      "restart_per_step execution works",
      "in_job_ext_tuner works for demo integration",
      "launcher wrappers support slurm/mpirun/torchrun with env propagation and logs"
    ]
  }
}
```
